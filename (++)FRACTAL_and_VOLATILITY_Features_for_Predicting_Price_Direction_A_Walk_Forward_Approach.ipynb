{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fractal and Volatility Features for Predicting Price Direction: A Walk-Forward Approach**"
      ],
      "metadata": {
        "id": "2XMK3gxdcyNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Introduction, Scope, and Limitation**\n",
        "\n",
        "\n",
        "**A. Introduction**\n",
        "\n",
        "\n",
        "This notebook presents a framework for building and evaluating a time-series classification model aimed at predicting directional price movements. It focuses on using fractal and volatility features derived *only* from past price data. The evaluation employs a rigorous walk-forward validation scheme with a purge period to prevent look-ahead bias, probability calibration to ensure reliable predictions, and a threshold optimization process to maximize the Matthews Correlation Coefficient (MCC). A basic PnL (Profit and Loss) sanity check is included at the end to give an initial sense of potential trading performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**B. Scope and Limitations**\n",
        "\n",
        "\n",
        "The scope is limited to predicting the *direction* of price movement over a fixed horizon using only the specified past price features. It does not attempt to predict the magnitude of price changes or incorporate external data sources. The backtesting is a simple sanity check and does not account for real-world factors like slippage (beyond basic transaction costs), exchange fees, funding costs (for leveraged positions), or realistic market microstructure effects. The model is trained and evaluated on historical data and its future performance is not guaranteed. The walk-forward setup, while robust, depends on the chosen fold sizes and gap.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**2. Model Modules and Implementation**\n",
        "\n",
        "\n",
        "The model is implemented using a pipeline approach, combining feature preprocessing (standardization) with a base classifier (XGBoost). Key aspects include:\n",
        "\n",
        "- **Feature Engineering:** Calculation of fractal features (Hurst Exponent via R/S, DFA alpha), volatility measures (realized volatility, bipower variation), and rolling autocorrelation of absolute returns. Optional wavelet energy features are also included.\n",
        "- **Labeling:** Supports both fixed-horizon log-return labeling with a dead zone and a triple-barrier method based on dynamic volatility thresholds and a maximum holding period.\n",
        "- **Walk-Forward Validation:** The core evaluation uses a time-series friendly walk-forward split with a purge period to maintain causality.\n",
        "- **Model Training:** An XGBoost classifier is used, with `scale_pos_weight` adjusted per-fold to handle class imbalance.\n",
        "- **Probability Calibration:** A `CalibratedClassifierCV` wrapper is used to improve the reliability of predicted probabilities, which are crucial for threshold optimization and risk management.\n",
        "- **Threshold Optimization:** The decision threshold for converting probabilities to binary predictions is optimized per-fold (or globally on OOF data) to maximize MCC.\n",
        "- **Evaluation Metrics:** Robust metrics are reported, including ROC-AUC, PR-AUC, Brier Score, and MCC.\n",
        "- **Diagnostics:** Includes a reliability diagram for calibration assessment and permutation feature importance for understanding feature relevance.\n",
        "- **PnL Sanity Check:** A basic backtest on out-of-fold data is performed to provide a preliminary view of potential strategy performance, incorporating simple transaction costs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "Limited to predicting price direction over a fixed horizon.\n",
        "Uses only specified past price features; no magnitude prediction or external data.\n",
        "Basic backtesting; does not account for slippage (beyond basic TC), fees, funding, microstructure.\n",
        "Future performance not guaranteed.\n",
        "Walk-forward setup depends on chosen fold sizes and gap."
      ],
      "metadata": {
        "id": "lbtX1geNWXzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Setup & Imports**"
      ],
      "metadata": {
        "id": "AnrUveU4_77e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed in a fresh env, uncomment to install:\n",
        "# !pip install --quiet numpy pandas scipy scikit-learn xgboost statsmodels pywavelets matplotlib yfinance\n",
        "\n",
        "import warnings, numpy as np, pandas as pd\n",
        "warnings.filterwarnings('ignore')\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n"
      ],
      "metadata": {
        "id": "5xQ4V1nz_vCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Configuration & Data Loading**"
      ],
      "metadata": {
        "id": "4XCG6mnH_-4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3 — Configuration & Data Loading (robust yfinance)\n",
        "\n",
        "USE_YFINANCE   = True       # fetch with yfinance\n",
        "USE_SYNTHETIC  = False      # not used when yfinance=True\n",
        "CSV_PATH       = 'your_prices.csv'  # unused here\n",
        "DATE_COL       = 'Date'\n",
        "\n",
        "# yfinance params\n",
        "TICKER = \"SPY\"          # or your preferred symbol, e.g., \"^GSPC\", \"AAPL\"\n",
        "START  = \"2015-01-01\"\n",
        "END    = \"2025-01-01\"\n",
        "\n",
        "def _flatten_yf_columns(df, ticker):\n",
        "    \"\"\"\n",
        "    Handle both shapes from yfinance:\n",
        "    - Single-level columns: ['Open','High','Low','Close','Adj Close','Volume']\n",
        "    - MultiIndex columns:\n",
        "        (a) top level = fields, second level = tickers\n",
        "        (b) top level = tickers, second level = fields\n",
        "    Returns a DataFrame with single-level columns for one ticker.\n",
        "    \"\"\"\n",
        "    if not isinstance(df.columns, pd.MultiIndex):\n",
        "        return df  # already flat\n",
        "\n",
        "    lvl0 = df.columns.get_level_values(0)\n",
        "    lvl1 = df.columns.get_level_values(1)\n",
        "\n",
        "    if ticker in lvl0:\n",
        "        sub = df[ticker]  # top level is ticker\n",
        "    elif ticker in lvl1:\n",
        "        sub = df.xs(ticker, axis=1, level=1)  # second level is ticker\n",
        "    else:\n",
        "        # Fallback: if only one ticker is present, use it\n",
        "        uniq0, uniq1 = sorted(set(lvl0)), sorted(set(lvl1))\n",
        "        if len(uniq0) == 1 and uniq0[0] not in ['Open','High','Low','Close','Adj Close','Volume']:\n",
        "            sub = df.xs(uniq0[0], axis=1, level=0)\n",
        "        elif len(uniq1) == 1:\n",
        "            sub = df.xs(uniq1[0], axis=1, level=1)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Ticker '{ticker}' not found in yfinance columns. \"\n",
        "                f\"Level0={uniq0[:6]}..., Level1={uniq1[:6]}...\"\n",
        "            )\n",
        "    # Ensure simple string column names\n",
        "    sub.columns = [str(c) for c in sub.columns]\n",
        "    return sub\n",
        "\n",
        "def load_price_data():\n",
        "    if USE_YFINANCE:\n",
        "        try:\n",
        "            import yfinance as yf\n",
        "        except ImportError:\n",
        "            raise ImportError(\"yfinance not installed. Uncomment the pip install cell in Section 2 and rerun.\")\n",
        "\n",
        "        # Be explicit: some versions differ on group_by default\n",
        "        df = yf.download(\n",
        "            TICKER, start=START, end=END,\n",
        "            auto_adjust=False, progress=False, group_by='ticker'\n",
        "        )\n",
        "        if df.empty:\n",
        "            raise ValueError(\"Downloaded data is empty. Check ticker or date range.\")\n",
        "\n",
        "        df = _flatten_yf_columns(df, TICKER)\n",
        "\n",
        "        # Standardize column names\n",
        "        cmap = {\n",
        "            'open':'Open','high':'High','low':'Low','close':'Close',\n",
        "            'adj close':'Adj Close','volume':'Volume'\n",
        "        }\n",
        "        df = df.rename(columns={c: cmap.get(c.lower(), c) for c in df.columns})\n",
        "\n",
        "        # Keep core OHLCV (drop missing if not present)\n",
        "        keep = [c for c in ['Open','High','Low','Close','Volume'] if c in df.columns]\n",
        "        df = df[keep].copy()\n",
        "\n",
        "        # Index → column \"Date\"\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df.index.name = 'Date'\n",
        "        df = df.sort_index()\n",
        "        df = df.loc[~df.index.duplicated(keep='first')]\n",
        "\n",
        "        # Clean types\n",
        "        for c in keep:\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "        df = df.dropna(subset=['Close']).reset_index()  # bring 'Date' back as a column\n",
        "\n",
        "    elif USE_SYNTHETIC:\n",
        "        # Not used when USE_YFINANCE=True, but kept for completeness\n",
        "        n = 4000\n",
        "        idx = pd.date_range('2015-01-01', periods=n, freq='B')\n",
        "        z = np.random.standard_t(df=5, size=n) * 0.008\n",
        "        vol = pd.Series(z).rolling(50).std().bfill().values\n",
        "        r = z * (0.6 + 4.0*vol)\n",
        "        price = 100*np.exp(pd.Series(r).cumsum())\n",
        "        close = price.values\n",
        "        high = close*(1+np.random.rand(n)*0.005)\n",
        "        low  = close*(1-n*np.random.rand(n)*0.005)\n",
        "        openp= close*(1+np.random.randn(n)*0.001)\n",
        "        volm = np.random.randint(1e5, 3e5, size=n)\n",
        "        df = pd.DataFrame({'Date':idx,'Open':openp,'High':high,'Low':low,'Close':close,'Volume':volm})\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        df = df.sort_values('Date').drop_duplicates('Date').reset_index(drop=True)\n",
        "\n",
        "    else:\n",
        "        # CSV fallback (unused here)\n",
        "        df = pd.read_csv(CSV_PATH)\n",
        "        df.columns = [c.strip() for c in df.columns]\n",
        "        ren = {}\n",
        "        for c in df.columns:\n",
        "            cl = c.lower()\n",
        "            if cl=='date': ren[c] = 'Date'\n",
        "            elif cl=='open': ren[c] = 'Open'\n",
        "            elif cl=='high': ren[c] = 'High'\n",
        "            elif cl=='low': ren[c] = 'Low'\n",
        "            elif cl=='close': ren[c] = 'Close'\n",
        "            elif cl=='volume': ren[c] = 'Volume'\n",
        "        df = df.rename(columns=ren)\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        df = df.sort_values('Date').drop_duplicates('Date').reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "prices = load_price_data()\n",
        "print(prices.head())\n",
        "print(f\"Loaded {len(prices)} rows from yfinance for {TICKER} [{START} → {END}].\")\n"
      ],
      "metadata": {
        "id": "g039OqrHAC7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.1. Basic helpers (returns, vol, ranges, rolling ACF of |returns|)**"
      ],
      "metadata": {
        "id": "2_YTawhfrpmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.1 Basic Helpers: returns, volatility, ranges, rolling ACF(|returns|) ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Iterable\n",
        "\n",
        "def logret(x: pd.Series) -> pd.Series:\n",
        "    \"\"\"Log returns of a price series.\"\"\"\n",
        "    return np.log(x).diff()\n",
        "\n",
        "def realized_vol(r: pd.Series, window: int = 20) -> pd.Series:\n",
        "    \"\"\"Annualized realized volatility over a rolling window.\"\"\"\n",
        "    return r.rolling(window).std() * np.sqrt(252)\n",
        "\n",
        "def bipower_variation(r: pd.Series, window: int = 20) -> pd.Series:\n",
        "    \"\"\"Bipower variation (annualized) as a robust volatility proxy.\"\"\"\n",
        "    lam = np.pi / 2\n",
        "    a = r.abs()\n",
        "    prod = a * a.shift(1)\n",
        "    return lam * prod.rolling(window).mean() * 252\n",
        "\n",
        "def hl_range(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"High–low range normalized by Close.\"\"\"\n",
        "    return (df['High'] - df['Low']) / df['Close']\n",
        "\n",
        "def rolling_acf_absr(series: pd.Series, lags: Iterable[int] = (1,2,3,4,5), window: int = 256) -> pd.DataFrame:\n",
        "    \"\"\"Rolling autocorrelation of absolute returns (volatility clustering proxy).\"\"\"\n",
        "    out = pd.DataFrame(index=series.index)\n",
        "    x = series.values\n",
        "    for lag in lags:\n",
        "        vals = []\n",
        "        for i in range(len(x)):\n",
        "            if i < window:\n",
        "                vals.append(np.nan)\n",
        "                continue\n",
        "            w = np.abs(x[i-window:i])\n",
        "            y = w[lag:]\n",
        "            z = w[:-lag]\n",
        "            if y.std(ddof=1) == 0 or z.std(ddof=1) == 0:\n",
        "                vals.append(np.nan)\n",
        "            else:\n",
        "                vals.append(np.corrcoef(y, z)[0, 1])\n",
        "        out[f'acf_absr_lag{lag}_{window}'] = vals\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "BTIByd_7r-Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.2. Fractal feature: Hurst exponent via rescaled-range (R/S)**"
      ],
      "metadata": {
        "id": "Zs2KyPFrrpde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.2 Hurst Exponent via R/S ---\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _rs_block(seg: np.ndarray) -> float:\n",
        "    y = seg - seg.mean()\n",
        "    z = np.cumsum(y)\n",
        "    R = z.max() - z.min()\n",
        "    S = y.std(ddof=1)\n",
        "    return np.log(R / S) if S > 0 else np.nan\n",
        "\n",
        "def rolling_hurst_rs(series: pd.Series, window: int = 512,\n",
        "                     scales = (16, 24, 36, 48, 64, 96, 128)) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Rolling Hurst estimate using multi-scale R/S regression.\n",
        "    Returns a per-row estimate using only past data.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    s = series.values.astype(float)\n",
        "    for i in range(len(s)):\n",
        "        if i < window:\n",
        "            out.append(np.nan)\n",
        "            continue\n",
        "        xw = s[i-window:i]\n",
        "        vals, ns = [], []\n",
        "        for n in scales:\n",
        "            if n >= window:\n",
        "                break\n",
        "            chunks = len(xw) // n\n",
        "            if chunks < 4:\n",
        "                continue\n",
        "            rs_vals = []\n",
        "            for k in range(chunks):\n",
        "                seg = xw[k*n:(k+1)*n]\n",
        "                rs = _rs_block(seg)\n",
        "                if not np.isnan(rs):\n",
        "                    rs_vals.append(np.exp(rs))  # back-transform before averaging\n",
        "            if len(rs_vals) >= 3:\n",
        "                vals.append(np.log(np.mean(rs_vals)))\n",
        "                ns.append(np.log(n))\n",
        "        if len(ns) >= 3:\n",
        "            X = sm.add_constant(ns)\n",
        "            beta = sm.OLS(vals, X).fit().params\n",
        "            H = beta[1]  # slope\n",
        "            out.append(H)\n",
        "        else:\n",
        "            out.append(np.nan)\n",
        "    return pd.Series(out, index=series.index, name=f\"H_RS_{window}\")\n"
      ],
      "metadata": {
        "id": "C6FrIe2st8i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.3. Fractal feature: DFA (detrended fluctuation analysis) alpha**"
      ],
      "metadata": {
        "id": "YLc8pp1drpUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.3 DFA Alpha ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def dfa_alpha(series: pd.Series, window: int = 512, order: int = 1,\n",
        "              scales = (16, 24, 36, 48, 64, 96, 128)) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Rolling DFA alpha using multi-scale regression on log F(n) vs log n.\n",
        "    Past-only per-row computation.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    x = series.values.astype(float)\n",
        "    for i in range(len(x)):\n",
        "        if i < window:\n",
        "            out.append(np.nan)\n",
        "            continue\n",
        "        w = x[i-window:i]\n",
        "        y = np.cumsum(w - w.mean())\n",
        "        Fn, ln_n = [], []\n",
        "        for n in scales:\n",
        "            if n >= window:\n",
        "                break\n",
        "            chunks = len(y) // n\n",
        "            if chunks < 4:\n",
        "                continue\n",
        "            errs = []\n",
        "            for k in range(chunks):\n",
        "                seg = y[k*n:(k+1)*n]\n",
        "                t = np.arange(n)\n",
        "                coeff = np.polyfit(t, seg, order)\n",
        "                trend = np.polyval(coeff, t)\n",
        "                errs.append(np.sqrt(np.mean((seg - trend) ** 2)))\n",
        "            Fn.append(np.mean(errs))\n",
        "            ln_n.append(np.log(n))\n",
        "        if len(ln_n) >= 3:\n",
        "            X = sm.add_constant(ln_n)\n",
        "            alpha = sm.OLS(np.log(Fn), X).fit().params[1]\n",
        "            out.append(alpha)\n",
        "        else:\n",
        "            out.append(np.nan)\n",
        "    return pd.Series(out, index=series.index, name=f\"DFA_{window}\")\n"
      ],
      "metadata": {
        "id": "_RxSWwLMuHbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate DFA alpha using the Close price series\n",
        "# You can adjust the window size as needed, matching the value used in feature engineering\n",
        "dfa_alpha_series = dfa_alpha(prices['Close'], window=512)\n",
        "\n",
        "# Plot the DFA alpha time series\n",
        "plt.figure(figsize=(12, 6))\n",
        "dfa_alpha_series.plot()\n",
        "plt.title('Rolling DFA Alpha of Close Price')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('DFA Alpha')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SQ05-BiMu2gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.4. Optional: wavelet energy features (toggleable)**"
      ],
      "metadata": {
        "id": "Ubgpblc3uK20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.4 Wavelet Energy (optional) ---\n",
        "# Toggle this to True if you want wavelet features (slower on long series)\n",
        "USE_WAVELETS = False\n",
        "WAVELET      = 'db2'\n",
        "WAVELET_LVL  = 4\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def wavelet_energy_features(series: pd.Series, window: int = 512,\n",
        "                            wavelet: str = 'db2', levels: int = 4) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Energy share of detail coefficients across levels (normalized) over a rolling window.\n",
        "    Imported locally so the cell runs even if PyWavelets isn't installed and you keep USE_WAVELETS=False.\n",
        "    \"\"\"\n",
        "    import pywt  # local import to avoid hard dependency if not using wavelets\n",
        "    idx = series.index\n",
        "    cols = {f'wl_Ed{j}_{window}': [] for j in range(1, levels+1)}\n",
        "    x = series.values\n",
        "    for i in range(len(x)):\n",
        "        if i < window:\n",
        "            for j in range(1, levels+1):\n",
        "                cols[f'wl_Ed{j}_{window}'].append(np.nan)\n",
        "            continue\n",
        "        w = x[i-window:i]\n",
        "        coeffs = pywt.wavedec(w, wavelet, level=levels)\n",
        "        details = coeffs[1:]                     # [cD_levels ... cD1]\n",
        "        en = [float(np.sum(d**2)) for d in details[::-1]]  # energy d1..dL\n",
        "        tot = sum(en)\n",
        "        for j, e in enumerate(en, start=1):\n",
        "            cols[f'wl_Ed{j}_{window}'].append((e / tot) if tot > 0 else np.nan)\n",
        "    return pd.DataFrame(cols, index=idx)\n"
      ],
      "metadata": {
        "id": "DA33Sv0TuOq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc333f9f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if USE_WAVELETS:\n",
        "    print(f\"Calculating wavelet energy features with wavelet='{WAVELET}' and levels={WAVELET_LVL}...\")\n",
        "    # Calculate wavelet energy features using the Close price series\n",
        "    # Adjust window, wavelet, and levels as needed\n",
        "    wavelet_features_df = wavelet_energy_features(\n",
        "        prices['Close'],\n",
        "        window=512, # Match window size used in feature engineering\n",
        "        wavelet=WAVELET,\n",
        "        levels=WAVELET_LVL\n",
        "    )\n",
        "\n",
        "    # Plot the wavelet energy features time series\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    wavelet_features_df.plot(ax=plt.gca()) # Plot on the current axes\n",
        "    plt.title('Rolling Wavelet Energy Features of Close Price')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Normalized Energy Share')\n",
        "    plt.grid(True)\n",
        "    plt.legend(title='Detail Level')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"USE_WAVELETS is set to False. Skipping wavelet feature calculation and plotting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.1. Label configuration**"
      ],
      "metadata": {
        "id": "vsHpxTPVwErW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.1 Label Configuration ---\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class LabelConfig:\n",
        "    method: str = 'horizon'   # 'horizon' or 'triple_barrier'\n",
        "    # Horizon labels\n",
        "    horizon: int = 20         # bars ahead\n",
        "    dead_zone: float = 0.0002 # ignore tiny moves (log-return threshold)\n",
        "    # Triple-barrier params\n",
        "    tb_pt: float = 2.0        # profit-taking multiple (× vol)\n",
        "    tb_sl: float = 2.0        # stop-loss multiple (× vol)\n",
        "    tb_max_h: int = 50        # max holding period (bars)\n",
        "    vol_ewm_span: int = 50    # span for EWM volatility estimator\n",
        "\n",
        "# choose your default here\n",
        "LABEL_CFG = LabelConfig(method='horizon', horizon=20, dead_zone=0.0002)\n"
      ],
      "metadata": {
        "id": "uig076o7wJNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.2. Horizon labeling (with dead-zone)**"
      ],
      "metadata": {
        "id": "u--ORAtgwEg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.2 Horizon Labeling (with dead-zone) ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_labels_horizon(df: pd.DataFrame, horizon: int = 20, dead_zone: float = 0.0) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Binary label from future log return over a fixed horizon.\n",
        "      y = 1 if future logret > +dead_zone\n",
        "      y = 0 if future logret < -dead_zone\n",
        "      y = NaN otherwise (ignored)\n",
        "    \"\"\"\n",
        "    px = df['Close'].astype(float)\n",
        "    fwd = np.log(px).shift(-horizon) - np.log(px)\n",
        "    y = pd.Series(np.nan, index=px.index)\n",
        "    y[fwd >  dead_zone] = 1\n",
        "    y[fwd < -dead_zone] = 0\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "c9v2nElHwQ-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.3. Triple-barrier labeling**"
      ],
      "metadata": {
        "id": "TN4L1OH6wEXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.3 Triple-Barrier Labeling ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_labels_triple_barrier(\n",
        "    df: pd.DataFrame,\n",
        "    pt_mult: float = 2.0,\n",
        "    sl_mult: float = 2.0,\n",
        "    max_h: int = 50,\n",
        "    vol_ewm_span: int = 50\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Triple-barrier labels:\n",
        "      - dynamic PT/SL set from EWM volatility of log returns\n",
        "      - outcome is which barrier is hit first (1=PT, 0=SL)\n",
        "      - if neither is hit by max_h, fallback to sign(px[t+max_h] - px[t])\n",
        "    \"\"\"\n",
        "    px = df['Close'].astype(float).values\n",
        "    idx = df.index\n",
        "    r = pd.Series(np.log(df['Close']).diff(), index=idx)\n",
        "    vol = r.ewm(span=vol_ewm_span).std().values\n",
        "\n",
        "    y = np.full(len(px), np.nan)\n",
        "    n = len(px)\n",
        "    for t in range(n):\n",
        "        if t >= n - 1:\n",
        "            break\n",
        "        p0 = px[t]\n",
        "        # dynamic barriers\n",
        "        up = p0 * np.exp(pt_mult * (vol[t] if not np.isnan(vol[t]) else 0.0))\n",
        "        dn = p0 * np.exp(-sl_mult * (vol[t] if not np.isnan(vol[t]) else 0.0))\n",
        "        last = min(t + max_h, n - 1)\n",
        "\n",
        "        label = np.nan\n",
        "        for u in range(t + 1, last + 1):\n",
        "            pu = px[u]\n",
        "            if pu >= up:\n",
        "                label = 1\n",
        "                break\n",
        "            if pu <= dn:\n",
        "                label = 0\n",
        "                break\n",
        "        if np.isnan(label):\n",
        "            # fallback at horizon end\n",
        "            label = 1 if px[last] > p0 else 0\n",
        "        y[t] = label\n",
        "\n",
        "    return pd.Series(y, index=idx, name='target')\n"
      ],
      "metadata": {
        "id": "WO_5DBuAwYtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.4. Label dispatcher + quick sanity check**"
      ],
      "metadata": {
        "id": "ZYImeTIqwEOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5.4 Label Dispatcher + Sanity Check ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def compute_labels(df: pd.DataFrame, cfg: LabelConfig) -> pd.Series:\n",
        "    if cfg.method == 'horizon':\n",
        "        return compute_labels_horizon(df, horizon=cfg.horizon, dead_zone=cfg.dead_zone)\n",
        "    elif cfg.method == 'triple_barrier':\n",
        "        return compute_labels_triple_barrier(\n",
        "            df,\n",
        "            pt_mult=cfg.tb_pt,\n",
        "            sl_mult=cfg.tb_sl,\n",
        "            max_h=cfg.tb_max_h,\n",
        "            vol_ewm_span=cfg.vol_ewm_span\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {cfg.method}\")\n",
        "\n",
        "# example: build labels now (features will be in Section 6)\n",
        "y_preview = compute_labels(prices, LABEL_CFG)\n",
        "print(\"Label preview (head):\")\n",
        "print(y_preview.head(10))\n",
        "print(\"\\nClass balance (ignoring NaNs):\")\n",
        "print(y_preview.value_counts(dropna=True).rename({0.0:\"class 0\", 1.0:\"class 1\"}))\n",
        "print(\"\\nNaN rate (dead-zone ignored rows):\", np.mean(y_preview.isna()).round(4))\n"
      ],
      "metadata": {
        "id": "bjtGwJQHwhYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.1. Feature params + base series**"
      ],
      "metadata": {
        "id": "i6bg9zpLwEFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6.1 Feature params + base series ---\n",
        "\n",
        "# Rolling window choices (tweak as you like)\n",
        "WIN_SHORT = 256\n",
        "WIN_LONG  = 512\n",
        "\n",
        "# Build base returns & simple vol/range features (all past-only)\n",
        "prices['logret'] = logret(prices['Close'])\n",
        "prices['hl_range'] = hl_range(prices)\n",
        "prices['rv20'] = realized_vol(prices['logret'], 20)\n",
        "prices['rv60'] = realized_vol(prices['logret'], 60)\n",
        "prices['bv20'] = bipower_variation(prices['logret'], 20)\n",
        "prices['bv60'] = bipower_variation(prices['logret'], 60)\n",
        "\n",
        "print(\"Base columns now available:\", [c for c in ['logret','hl_range','rv20','rv60','bv20','bv60'] if c in prices.columns])\n",
        "prices[['Date','Close','logret','rv20','hl_range']].head()\n"
      ],
      "metadata": {
        "id": "Mz02HwP3w7E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.2. Compute fractal, ACF, and optional wavelet features**"
      ],
      "metadata": {
        "id": "FvmrChhhw1Ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6.2 Compute fractal, ACF, and optional wavelet features ---\n",
        "\n",
        "# Fractal (Hurst via R/S and DFA) on log returns\n",
        "H_RS_256 = rolling_hurst_rs(prices['logret'].fillna(0.0), window=WIN_SHORT)\n",
        "H_RS_512 = rolling_hurst_rs(prices['logret'].fillna(0.0), window=WIN_LONG)\n",
        "DFA_256  = dfa_alpha(prices['logret'].fillna(0.0), window=WIN_SHORT)\n",
        "DFA_512  = dfa_alpha(prices['logret'].fillna(0.0), window=WIN_LONG)\n",
        "\n",
        "# Volatility clustering proxy: rolling ACF of |returns|\n",
        "ACF_256  = rolling_acf_absr(prices['logret'].fillna(0.0), lags=(1,2,3,4,5), window=WIN_SHORT)\n",
        "\n",
        "# Optional wavelet energy features\n",
        "WL_512 = None\n",
        "if 'USE_WAVELETS' in globals() and USE_WAVELETS:\n",
        "    WL_512 = wavelet_energy_features(prices['logret'].fillna(0.0), window=WIN_LONG,\n",
        "                                     wavelet=WAVELET, levels=WAVELET_LVL)\n",
        "    print(\"Wavelet features computed:\", WL_512.columns.tolist())\n",
        "\n",
        "print(\"Fractal/ACF features ready.\")\n"
      ],
      "metadata": {
        "id": "Z23MDI3KxTWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.3. Assemble X and y, align & clean, preview**"
      ],
      "metadata": {
        "id": "NYkX5oRLw1Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6.3 Assemble X and y, align & clean, preview ---\n",
        "\n",
        "# Collect features into one table\n",
        "feature_blocks = [\n",
        "    prices[['hl_range','rv20','rv60','bv20','bv60']],\n",
        "    H_RS_256, H_RS_512, DFA_256, DFA_512,\n",
        "    ACF_256\n",
        "]\n",
        "if WL_512 is not None:\n",
        "    feature_blocks.append(WL_512)\n",
        "\n",
        "X = pd.concat(feature_blocks, axis=1)\n",
        "\n",
        "# Labels (from Section 5)\n",
        "y = compute_labels(prices, LABEL_CFG)\n",
        "\n",
        "# Combine & drop rows with NaNs from rolling windows and dead-zone NaNs\n",
        "df_all = pd.concat([prices[[DATE_COL, 'Close']], X, y.rename('target')], axis=1)\n",
        "df_all = df_all.dropna().reset_index(drop=True)\n",
        "\n",
        "# Final X/y\n",
        "X_final = df_all.drop(columns=[DATE_COL, 'Close', 'target'])\n",
        "y_final = df_all['target'].astype(int)\n",
        "\n",
        "print(\"Dataset ready.\")\n",
        "print(\"X shape:\", X_final.shape, \"| y positives:\", int(y_final.sum()), \"/\", len(y_final),\n",
        "      \"| pos rate:\", round(y_final.mean(), 4))\n",
        "print(\"\\nFeature sample:\")\n",
        "display(X_final.head(10))\n",
        "\n",
        "# Optional: save for inspection\n",
        "# X_final.to_csv(\"X_features.csv\", index=False)\n",
        "# y_final.to_csv(\"y_labels.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "yh_mRH4vxb5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70e94425"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Plot histograms for all features in X_final\n",
        "print(\"Plotting histograms for all features:\")\n",
        "X_final.hist(figsize=(15, 10), bins=50)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d1b5296"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Select a few features to plot as time series\n",
        "# Choosing one from each category (range, volatility, Hurst, DFA, ACF)\n",
        "selected_features = [\n",
        "    'hl_range',\n",
        "    'rv20',\n",
        "    'H_RS_512',\n",
        "    'DFA_512',\n",
        "    'acf_absr_lag1_256',\n",
        "]\n",
        "\n",
        "# Add wavelet features if they exist and were used\n",
        "if 'wl_Ed1_512' in X_final.columns:\n",
        "     # Add the first detail level wavelet energy feature\n",
        "     selected_features.append('wl_Ed1_512')\n",
        "\n",
        "\n",
        "print(\"Plotting time series for selected features:\")\n",
        "# Use the original index from df_all for time series plotting\n",
        "# df_all was created before dropping NaNs and resetting index, but keeping relevant columns\n",
        "# Need to re-create a temporary df with Date index for plotting X_final with dates\n",
        "temp_df = df_all[['Date'] + selected_features].set_index('Date')\n",
        "\n",
        "temp_df.plot(figsize=(15, 10), subplots=True, layout=(-1, 2)) # Plot in subplots, 2 columns\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.1. Walk-forward config + helpers (splits, metrics, threshold search)**"
      ],
      "metadata": {
        "id": "AvxsekR6yUlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7.1 Walk-forward config + helpers ---\n",
        "\n",
        "from typing import Iterator, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Heuristics for fold sizes (tweak as needed)\n",
        "N_TOTAL   = len(y_final)\n",
        "NUM_TRAIN = max(1000, int(N_TOTAL * 0.55))   # training rows per fold\n",
        "NUM_TEST  = max(200,  int(N_TOTAL * 0.15))   # test rows per fold\n",
        "GAP       = 5                                # purge gap between train and test\n",
        "\n",
        "def forward_splits(n: int, train: int, test: int, gap: int = 0) -> Iterator[Tuple[slice, slice]]:\n",
        "    \"\"\"\n",
        "    Yield (train_slice, test_slice) for a walk-forward scheme with a purge gap.\n",
        "    Train/test are **lengths**, not indices. Slices are 0-based, half-open.\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    while i + train + gap + test <= n:\n",
        "        tr = slice(i, i + train)\n",
        "        te = slice(i + train + gap, i + train + gap + test)\n",
        "        yield tr, te\n",
        "        i += test  # slide window by test length each fold\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, brier_score_loss,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "\n",
        "def evaluate_probs(y_true: np.ndarray, p: np.ndarray, thr: float = 0.5) -> dict:\n",
        "    \"\"\"Return a dict of robust metrics for probabilistic outputs.\"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    p = np.asarray(p)\n",
        "    yhat = (p >= thr).astype(int)\n",
        "    return dict(\n",
        "        roc_auc = float(roc_auc_score(y_true, p)),\n",
        "        pr_auc  = float(average_precision_score(y_true, p)),\n",
        "        brier   = float(brier_score_loss(y_true, p)),\n",
        "        mcc     = float(matthews_corrcoef(y_true, yhat)),\n",
        "    )\n",
        "\n",
        "def best_threshold(y_true: np.ndarray, p: np.ndarray, metric: str = \"mcc\") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Grid-search the decision threshold in [0.05..0.95] to maximize MCC (default).\n",
        "    Returns (best_threshold, best_score).\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    p = np.asarray(p)\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_v = 0.5, -np.inf\n",
        "    for t in grid:\n",
        "        v = matthews_corrcoef(y_true, (p >= t).astype(int))\n",
        "        if v > best_v:\n",
        "            best_t, best_v = float(t), float(v)\n",
        "    return best_t, best_v\n"
      ],
      "metadata": {
        "id": "wDP25eOYywPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.2. Model: pipeline + calibration, walk-forward training loop**"
      ],
      "metadata": {
        "id": "i8gQh6WsyUM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7.2 Pipeline + calibration, walk-forward loop ---\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Calibration method: 'sigmoid' is safer on small samples; switch to 'isotonic' if you have plenty of data.\n",
        "CALIB_METHOD = \"sigmoid\"\n",
        "\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "def make_pipeline(scale_pos_weight: float = 1.0) -> Pipeline:\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[(\"num\", StandardScaler(), numeric_cols)],\n",
        "        remainder=\"drop\",\n",
        "        verbose_feature_names_out=False\n",
        "    )\n",
        "    base = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=4,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.0,\n",
        "        tree_method=\"hist\",\n",
        "        random_state=42,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    # Correct parameter name from base_estimator to estimator\n",
        "    clf = CalibratedClassifierCV(estimator=base, cv=3, method=CALIB_METHOD)\n",
        "    pipe = Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
        "    return pipe\n",
        "\n",
        "# Walk-forward training\n",
        "all_probs = np.full(shape=len(y_final), fill_value=np.nan, dtype=float)\n",
        "fold_rows = []\n",
        "fold_id = 0\n",
        "\n",
        "for tr, te in forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP):\n",
        "    fold_id += 1\n",
        "    X_tr, y_tr = X_final.iloc[tr], y_final.iloc[tr]\n",
        "    X_te, y_te = X_final.iloc[te], y_final.iloc[te]\n",
        "\n",
        "    # class imbalance handling via scale_pos_weight = neg/pos\n",
        "    pos = int(y_tr.sum())\n",
        "    neg = int(len(y_tr) - pos)\n",
        "    spw = (neg / pos) if pos > 0 else 1.0\n",
        "\n",
        "    model = make_pipeline(scale_pos_weight=spw)\n",
        "    model.fit(X_tr, y_tr)\n",
        "\n",
        "    p = model.predict_proba(X_te)[:, 1]\n",
        "    all_probs[te] = p\n",
        "\n",
        "    # quick per-fold metrics at 0.5 threshold\n",
        "    m = evaluate_probs(y_te.values, p, thr=0.5)\n",
        "    fold_rows.append(dict(\n",
        "        fold=fold_id, n_train=int(len(y_tr)), n_test=int(len(y_te)),\n",
        "        pos_rate_train=float(y_tr.mean()), pos_rate_test=float(y_te.mean()),\n",
        "        **m\n",
        "    ))\n",
        "\n",
        "fold_metrics = pd.DataFrame(fold_rows)\n",
        "print(\"Per-fold metrics (thr=0.5):\")\n",
        "display(fold_metrics)\n",
        "print(\"\\nAverages (± std):\")\n",
        "print(fold_metrics[['roc_auc','pr_auc','brier','mcc']].agg(['mean','std']).round(4))"
      ],
      "metadata": {
        "id": "MLuThc4iy4vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.3. Out-of-fold aggregation + threshold optimization**"
      ],
      "metadata": {
        "id": "g65-mmCfyUD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7.3 OOF aggregation + threshold optimization ---\n",
        "\n",
        "mask = ~np.isnan(all_probs)\n",
        "y_oof = y_final.values[mask]\n",
        "p_oof = all_probs[mask]\n",
        "\n",
        "print(f\"OOF coverage: {mask.sum()} / {len(y_final)} rows\")\n",
        "\n",
        "# Metrics at default 0.5 threshold\n",
        "base_scores = evaluate_probs(y_oof, p_oof, thr=0.5)\n",
        "print(\"\\nOOF metrics @ thr=0.5:\", {k: round(v, 4) for k, v in base_scores.items()})\n",
        "\n",
        "# Optimize threshold for MCC\n",
        "t_best, m_best = best_threshold(y_oof, p_oof, metric=\"mcc\")\n",
        "opt_scores = evaluate_probs(y_oof, p_oof, thr=t_best)\n",
        "\n",
        "print(f\"\\nBest threshold by MCC: {t_best:.3f}  (MCC={m_best:.4f})\")\n",
        "print(\"OOF metrics @ best thr:\", {k: round(v, 4) for k, v in opt_scores.items()})\n",
        "\n",
        "# Confusion matrix at best threshold (optional)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_oof, (p_oof >= t_best).astype(int), labels=[0,1])\n",
        "cm_df = pd.DataFrame(cm, index=[\"true_0\",\"true_1\"], columns=[\"pred_0\",\"pred_1\"])\n",
        "print(\"\\nConfusion matrix @ best thr:\")\n",
        "display(cm_df)\n",
        "\n",
        "# Keep the OOF predictions if you want to analyze later\n",
        "oof_df = pd.DataFrame({\n",
        "    DATE_COL: df_all[DATE_COL].values[mask],\n",
        "    \"y_true\": y_oof,\n",
        "    \"p_hat\":  p_oof\n",
        "})\n",
        "print(\"\\nOOF sample:\")\n",
        "display(oof_df.head(10))\n"
      ],
      "metadata": {
        "id": "4pO4QmRqzQW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.1. Reliability diagram (calibration curve) from OOF predictions**"
      ],
      "metadata": {
        "id": "iNmktNX52dcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8.1 Reliability diagram (calibration curve) ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# guards\n",
        "assert 'p_oof' in globals() and 'y_oof' in globals(), \"Run Section 7 first (OOF predictions).\"\n",
        "\n",
        "prob_true, prob_pred = calibration_curve(y_oof, p_oof, n_bins=12, strategy=\"quantile\")\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(prob_pred, prob_true, marker=\"o\", linewidth=1)\n",
        "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
        "plt.xlabel(\"Predicted probability\")\n",
        "plt.ylabel(\"Empirical frequency\")\n",
        "plt.title(\"Reliability Diagram (OOF)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# simple calibration diagnostics\n",
        "ece = float(np.mean(np.abs(prob_true - prob_pred)))\n",
        "print(f\"Expected Calibration Error (ECE), ~heuristic: {ece:.4f}\")\n"
      ],
      "metadata": {
        "id": "W04R0odd2qU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.2. Permutation feature importance (quick, holdout-style)**"
      ],
      "metadata": {
        "id": "ajrGbRTo2eLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8.2 Permutation Feature Importance (holdout-style) ---\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We recompute a single fitted model on a holdout split (approximate)\n",
        "X_tr, X_ho, y_tr, y_ho = train_test_split(\n",
        "    X_final, y_final, test_size=0.25, shuffle=False\n",
        ")\n",
        "\n",
        "# rebalance weight using in-sample class ratio\n",
        "pos = int(y_tr.sum()); neg = int(len(y_tr) - pos)\n",
        "spw = (neg/pos) if pos>0 else 1.0\n",
        "tmp_model = make_pipeline(scale_pos_weight=spw)  # from Section 7.2\n",
        "tmp_model.fit(X_tr, y_tr)\n",
        "\n",
        "# PI on the holdout set using ROC-AUC as the score\n",
        "pi = permutation_importance(\n",
        "    tmp_model, X_ho, y_ho,\n",
        "    n_repeats=10, scoring=\"roc_auc\", random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "imp_df = pd.DataFrame({\n",
        "    \"feature\": X_final.columns,\n",
        "    \"importance_mean\": pi.importances_mean,\n",
        "    \"importance_std\":  pi.importances_std\n",
        "}).sort_values(\"importance_mean\", ascending=False)\n",
        "\n",
        "print(\"Top 20 features by permutation importance (ROC-AUC on holdout):\")\n",
        "display(imp_df.head(20))\n"
      ],
      "metadata": {
        "id": "ejJgD5Ei21w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.1. Backtest helpers**"
      ],
      "metadata": {
        "id": "5x7_6M_82e26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 9.1 Backtest helpers ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def performance_stats(equity_curve, freq=252):\n",
        "    \"\"\"Return simple CAGR, Sharpe (daily->annual), and max drawdown.\"\"\"\n",
        "    rets = np.log(equity_curve).diff().dropna()\n",
        "    ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "    ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "    sharpe = float(ann_ret / ann_vol) if ann_vol>0 else np.nan\n",
        "    peak = equity_curve.cummax()\n",
        "    dd = (equity_curve/peak - 1.0)\n",
        "    mdd = float(dd.min())\n",
        "    return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "def backtest_from_oof(oof_df, prices, t_best, tc_bps=5, mode=\"long_only\"):\n",
        "    \"\"\"\n",
        "    mode:\n",
        "      - 'long_only': pos=1 if p>=t_best else 0\n",
        "      - 'long_short': pos=+1 if p>=t_best, -1 if p<=1-t_best, else 0\n",
        "    tc_bps: transaction cost in basis points per trade (applied on position change)\n",
        "    \"\"\"\n",
        "    df = oof_df.merge(prices[[DATE_COL, 'logret']], on=DATE_COL, how='left')  # logret computed in 6.1\n",
        "    df = df.sort_values(DATE_COL).reset_index(drop=True)\n",
        "\n",
        "    # Next-period log-return as trade PnL driver\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "\n",
        "    if mode == \"long_only\":\n",
        "        df['pos'] = (df['p_hat'] >= t_best).astype(int)\n",
        "    elif mode == \"long_short\":\n",
        "        df['pos'] = 0\n",
        "        df.loc[df['p_hat'] >= t_best, 'pos'] = 1\n",
        "        df.loc[df['p_hat'] <= (1 - t_best), 'pos'] = -1\n",
        "    else:\n",
        "        raise ValueError(\"Unknown mode\")\n",
        "\n",
        "    # apply position with one-bar delay (enter next bar)\n",
        "    df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "\n",
        "    # turnover and transaction cost\n",
        "    df['turnover'] = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    tc = (tc_bps / 1e4)  # convert bps to decimal\n",
        "    df['ret_strategy'] = df['pos_shift'] * df['r1'] - df['turnover'] * tc\n",
        "\n",
        "    # equity curve\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    stats = performance_stats(df['equity'])\n",
        "\n",
        "    return df, stats\n"
      ],
      "metadata": {
        "id": "s5N5AV9o3Kdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.2. Run backtest (long-only & long/short), plot curves, print stats**"
      ],
      "metadata": {
        "id": "mShxIzjF3PnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 9.2 Run PnL sanity check ---\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# guards\n",
        "assert 'oof_df' in globals() and 't_best' in globals(), \"Run Section 7.3 first.\"\n",
        "\n",
        "# Long-only\n",
        "bt_long, st_long = backtest_from_oof(oof_df, prices, t_best=t_best, tc_bps=5, mode=\"long_only\")\n",
        "# Long/short (neutral zone between 1-t_best and t_best)\n",
        "bt_ls, st_ls = backtest_from_oof(oof_df, prices, t_best=t_best, tc_bps=5, mode=\"long_short\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,4))\n",
        "ax.plot(bt_long[DATE_COL], bt_long['equity'], label=\"Long-only\")\n",
        "ax.plot(bt_ls[DATE_COL],   bt_ls['equity'],   label=\"Long/Short\")\n",
        "ax.set_title(\"Simple Strategy Equity (OOF, with costs)\")\n",
        "ax.set_xlabel(DATE_COL)\n",
        "ax.set_ylabel(\"Equity (start=1.0)\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Long-only stats:\", {k: round(v,4) for k,v in st_long.items()})\n",
        "print(\"Long/Short stats:\", {k: round(v,4) for k,v in st_ls.items()})\n"
      ],
      "metadata": {
        "id": "kLamVTTC3V6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10.1. Compile a summary report (fold metrics, OOF metrics, calibration, PnL)**"
      ],
      "metadata": {
        "id": "c3zwAeU93Pdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10.1 Compact Summary Report ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def exists(name: str) -> bool:\n",
        "    return name in globals()\n",
        "\n",
        "summary = {}\n",
        "\n",
        "# Context\n",
        "summary[\"ticker\"]      = TICKER if exists(\"TICKER\") else None\n",
        "summary[\"date_range\"]  = f\"{START} → {END}\" if exists(\"START\") and exists(\"END\") else None\n",
        "summary[\"n_rows_raw\"]  = int(len(prices)) if exists(\"prices\") else None\n",
        "summary[\"n_rows_model\"] = int(len(y_final)) if exists(\"y_final\") else None\n",
        "summary[\"n_features\"]  = int(X_final.shape[1]) if exists(\"X_final\") else None\n",
        "summary[\"label_method\"]= LABEL_CFG.method if exists(\"LABEL_CFG\") else None\n",
        "summary[\"label_params\"]= dict(LABEL_CFG.__dict__) if exists(\"LABEL_CFG\") else None\n",
        "\n",
        "# Per-fold metrics at thr=0.5\n",
        "if exists(\"fold_metrics\"):\n",
        "    fm_cols = ['roc_auc','pr_auc','brier','mcc']\n",
        "    summary[\"fold_metrics_mean\"] = fold_metrics[fm_cols].mean().round(4).to_dict()\n",
        "    summary[\"fold_metrics_std\"]  = fold_metrics[fm_cols].std().round(4).to_dict()\n",
        "    summary[\"folds\"] = int(len(fold_metrics))\n",
        "else:\n",
        "    summary[\"fold_metrics_mean\"] = None\n",
        "    summary[\"fold_metrics_std\"]  = None\n",
        "    summary[\"folds\"] = None\n",
        "\n",
        "# OOF metrics at 0.5 and best threshold\n",
        "if exists(\"p_oof\") and exists(\"y_oof\"):\n",
        "    from sklearn.metrics import matthews_corrcoef, roc_auc_score, average_precision_score, brier_score_loss\n",
        "    def scores_at_thr(y, p, thr):\n",
        "        yhat = (p>=thr).astype(int)\n",
        "        return dict(\n",
        "            roc_auc = round(roc_auc_score(y, p), 4),\n",
        "            pr_auc  = round(average_precision_score(y, p), 4),\n",
        "            brier   = round(brier_score_loss(y, p), 5),\n",
        "            mcc     = round(matthews_corrcoef(y, yhat), 4),\n",
        "        )\n",
        "    # Default thr=0.5\n",
        "    summary[\"oof_thr_0p5\"] = scores_at_thr(y_oof, p_oof, 0.5)\n",
        "    # Best-MCC threshold (if computed)\n",
        "    if exists(\"t_best\") and exists(\"m_best\"):\n",
        "        summary[\"oof_thr_best\"] = scores_at_thr(y_oof, p_oof, t_best)\n",
        "        summary[\"best_threshold_mcc\"] = dict(threshold=round(float(t_best),3), mcc=round(float(m_best),4))\n",
        "    else:\n",
        "        summary[\"oof_thr_best\"] = None\n",
        "        summary[\"best_threshold_mcc\"] = None\n",
        "    summary[\"oof_coverage\"] = f\"{np.isfinite(p_oof).sum()} / {len(y_final)}\"\n",
        "else:\n",
        "    summary[\"oof_thr_0p5\"] = None\n",
        "    summary[\"oof_thr_best\"] = None\n",
        "    summary[\"oof_coverage\"] = None\n",
        "\n",
        "# Calibration (ECE) if computed\n",
        "summary[\"ece\"] = round(float(ece), 5) if exists(\"ece\") else None\n",
        "\n",
        "# PnL sanity check stats\n",
        "if exists(\"st_long\") and exists(\"st_ls\"):\n",
        "    def round_stats(d): return {k: round(v, 4) if isinstance(v, (int,float,np.floating)) else v for k,v in d.items()}\n",
        "    summary[\"pnl_long_only\"] = round_stats(st_long)\n",
        "    summary[\"pnl_long_short\"] = round_stats(st_ls)\n",
        "else:\n",
        "    summary[\"pnl_long_only\"] = None\n",
        "    summary[\"pnl_long_short\"] = None\n",
        "\n",
        "# Show a tidy table view\n",
        "report_df = pd.DataFrame(pd.json_normalize(summary, sep='__')).T\n",
        "print(\"=== Fractal Model Summary Report ===\")\n",
        "display(report_df)\n",
        "\n",
        "# Friendly text summary\n",
        "print(\"\\n--- Human-friendly summary ---\")\n",
        "print(f\"Ticker: {summary['ticker']} | Period: {summary['date_range']}\")\n",
        "print(f\"Rows (raw/model): {summary['n_rows_raw']} / {summary['n_rows_model']} | Features: {summary['n_features']}\")\n",
        "print(f\"Labeling: {summary['label_method']}  params={summary['label_params']}\")\n",
        "if summary['folds']:\n",
        "    m = summary['fold_metrics_mean']; s = summary['fold_metrics_std']\n",
        "    print(f\"Per-fold (mean±std) -> ROC-AUC: {m['roc_auc']:.3f}±{s['roc_auc']:.3f}, \"\n",
        "          f\"PR-AUC: {m['pr_auc']:.3f}±{s['pr_auc']:.3f}, Brier: {m['brier']:.4f}±{s['brier']:.4f}, \"\n",
        "          f\"MCC: {m['mcc']:.3f}±{s['mcc']:.3f}\")\n",
        "if summary['oof_thr_0p5']:\n",
        "    print(f\"OOF @0.5: {summary['oof_thr_0p5']}\")\n",
        "if summary['oof_thr_best']:\n",
        "    print(f\"Best threshold by MCC: {summary['best_threshold_mcc']}\")\n",
        "    print(f\"OOF @best: {summary['oof_thr_best']}\")\n",
        "if summary['ece'] is not None:\n",
        "    print(f\"Calibration ECE (lower is better): {summary['ece']:.4f}\")\n",
        "if summary['pnl_long_only']:\n",
        "    print(f\"PnL Long-only:  {summary['pnl_long_only']}\")\n",
        "    print(f\"PnL Long/Short: {summary['pnl_long_short']}\")\n"
      ],
      "metadata": {
        "id": "-NJujzSK37RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10.x. Save labeled artifacts for comparison (baseline & tuned)**"
      ],
      "metadata": {
        "id": "dXbRYtg47Jpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10.x Save labeled artifacts (baseline & tuned) ---\n",
        "\n",
        "import os, json\n",
        "import pandas as pd\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "\n",
        "def _safe_save_csv(df, path):\n",
        "    try:\n",
        "        df.to_csv(path, index=False)\n",
        "        print(\"saved:\", path)\n",
        "    except Exception as e:\n",
        "        print(\"skip saving\", path, \"->\", e)\n",
        "\n",
        "def _safe_save_json(obj, path):\n",
        "    try:\n",
        "        with open(path, \"w\") as f:\n",
        "            json.dump(obj, f, indent=2)\n",
        "        print(\"saved:\", path)\n",
        "    except Exception as e:\n",
        "        print(\"skip saving\", path, \"->\", e)\n",
        "\n",
        "# Try to detect “baseline” (pre-tuning) items in memory\n",
        "baseline_detected = all(name in globals() for name in [\n",
        "    \"fold_metrics\", \"p_oof\", \"y_oof\", \"t_best\", \"m_best\"\n",
        "]) and \"fold_metrics_tuned\" not in globals()\n",
        "\n",
        "tuned_detected = all(name in globals() for name in [\n",
        "    \"fold_metrics_tuned\", \"p_oof_tuned\", \"y_oof_tuned\", \"t_best_tuned\", \"m_best_tuned\"\n",
        "])\n",
        "\n",
        "# Build a minimal summary dict from current globals (works for either baseline or tuned)\n",
        "def build_summary_dict(tag=\"current\"):\n",
        "    out = dict(\n",
        "        tag=tag,\n",
        "        ticker=TICKER if \"TICKER\" in globals() else None,\n",
        "        date_range=f\"{START} → {END}\" if \"START\" in globals() and \"END\" in globals() else None,\n",
        "        n_rows_raw=int(len(prices)) if \"prices\" in globals() else None,\n",
        "        n_rows_model=int(len(y_final)) if \"y_final\" in globals() else None,\n",
        "        n_features=int(X_final.shape[1]) if \"X_final\" in globals() else None,\n",
        "        label_method=LABEL_CFG.method if \"LABEL_CFG\" in globals() else None,\n",
        "        label_params=dict(LABEL_CFG.__dict__) if \"LABEL_CFG\" in globals() else None\n",
        "    )\n",
        "    return out\n",
        "\n",
        "# If you still have baseline in memory, snapshot it explicitly\n",
        "if baseline_detected:\n",
        "    _safe_save_csv(fold_metrics, \"artifacts/fold_metrics_baseline.csv\")\n",
        "    # try to persist OOF too\n",
        "    if \"oof_df\" in globals():\n",
        "        _safe_save_csv(oof_df, \"artifacts/oof_predictions_baseline.csv\")\n",
        "    _safe_save_json(build_summary_dict(\"baseline\"), \"artifacts/report_summary_baseline.json\")\n",
        "\n",
        "# If you have tuned objects (from Section 11.3), snapshot them\n",
        "if tuned_detected:\n",
        "    _safe_save_csv(fold_metrics_tuned, \"artifacts/fold_metrics_tuned.csv\")\n",
        "    tuned_oof = pd.DataFrame({\n",
        "        DATE_COL: df_all[DATE_COL].values[~pd.isna(p_oof_tuned)],\n",
        "        \"y_true\": y_oof_tuned,\n",
        "        \"p_hat\":  p_oof_tuned\n",
        "    })\n",
        "    _safe_save_csv(tuned_oof, \"artifacts/oof_predictions_tuned.csv\")\n",
        "    _safe_save_json(build_summary_dict(\"tuned\"), \"artifacts/report_summary_tuned.json\")\n",
        "\n",
        "print(\"Done. If you didn’t have baseline in memory, you can still compare tuned vs whatever’s saved previously in artifacts/.\")\n"
      ],
      "metadata": {
        "id": "9ZT7DP5w7MF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10.y. Baseline vs tuned comparison table (means, deltas, OOF)**\n",
        "\n",
        "    This will load from memory if available, otherwise from artifacts/… files."
      ],
      "metadata": {
        "id": "cCob54wf6F7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10.y Baseline vs Tuned comparison report ---\n",
        "\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def try_load_csv(*paths):\n",
        "    for p in paths:\n",
        "        if os.path.exists(p):\n",
        "            return pd.read_csv(p)\n",
        "    return None\n",
        "\n",
        "def try_load_json(*paths):\n",
        "    for p in paths:\n",
        "        if os.path.exists(p):\n",
        "            with open(p) as f:\n",
        "                return json.load(f)\n",
        "    return None\n",
        "\n",
        "# 1) Fold metrics (mean±std)\n",
        "fm_base = globals().get(\"fold_metrics\", None)\n",
        "fm_tuned = globals().get(\"fold_metrics_tuned\", None)\n",
        "\n",
        "if fm_base is None:\n",
        "    fm_base = try_load_csv(\"artifacts/fold_metrics_baseline.csv\", \"artifacts/fold_metrics.csv\")  # fallback\n",
        "\n",
        "if fm_tuned is None:\n",
        "    fm_tuned = try_load_csv(\"artifacts/fold_metrics_tuned.csv\")\n",
        "\n",
        "def summarize_folds(df):\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "    cols = ['roc_auc','pr_auc','brier','mcc']\n",
        "    for c in cols:\n",
        "        if c not in df.columns:\n",
        "            return None\n",
        "    return df[cols].agg(['mean','std']).round(4)\n",
        "\n",
        "sum_base = summarize_folds(fm_base)\n",
        "sum_tuned = summarize_folds(fm_tuned)\n",
        "\n",
        "print(\"=== Fold metrics (mean ± std) ===\")\n",
        "if sum_base is not None:\n",
        "    print(\"\\nBaseline:\")\n",
        "    display(sum_base)\n",
        "else:\n",
        "    print(\"\\nBaseline: not found\")\n",
        "\n",
        "if sum_tuned is not None:\n",
        "    print(\"\\nTuned:\")\n",
        "    display(sum_tuned)\n",
        "else:\n",
        "    print(\"\\nTuned: not found\")\n",
        "\n",
        "if sum_base is not None and sum_tuned is not None:\n",
        "    delta = (sum_tuned.loc['mean'] - sum_base.loc['mean']).to_frame('delta_mean').T\n",
        "    print(\"\\nΔ (Tuned − Baseline), means only:\")\n",
        "    display(delta.round(4))\n",
        "\n",
        "# 2) OOF comparison at thr=0.5 and best-MCC\n",
        "def oof_scores(y, p, thr):\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, matthews_corrcoef\n",
        "    return dict(\n",
        "        roc_auc=round(float(roc_auc_score(y, p)),4),\n",
        "        pr_auc=round(float(average_precision_score(y, p)),4),\n",
        "        brier=round(float(brier_score_loss(y, p)),5),\n",
        "        mcc=round(float(matthews_corrcoef(y, (p>=thr).astype(int))),4),\n",
        "        thr=round(float(thr),3)\n",
        "    )\n",
        "\n",
        "# Try memory first\n",
        "y_base = globals().get(\"y_oof\", None)\n",
        "p_base = globals().get(\"p_oof\", None)\n",
        "t_base = globals().get(\"t_best\", 0.5)\n",
        "\n",
        "# If memory currently points to tuned, try loading explicit baseline OOF\n",
        "if \"fold_metrics_tuned\" in globals():\n",
        "    # You probably overwrote OOF with tuned; load baseline OOF from artifacts if present\n",
        "    oof_base_df = try_load_csv(\"artifacts/oof_predictions_baseline.csv\")\n",
        "    if oof_base_df is not None:\n",
        "        y_base = oof_base_df[\"y_true\"].values\n",
        "        p_base = oof_base_df[\"p_hat\"].values\n",
        "        # Use same threshold as best for baseline if we saved it somewhere else; otherwise compute quickly:\n",
        "        from sklearn.metrics import matthews_corrcoef\n",
        "        grid = np.linspace(0.05, 0.95, 37)\n",
        "        best_m, best_t = -1, 0.5\n",
        "        for t in grid:\n",
        "            m = matthews_corrcoef(y_base, (p_base>=t).astype(int))\n",
        "            if m>best_m:\n",
        "                best_m, best_t = m, t\n",
        "        t_base = best_t\n",
        "\n",
        "# Load tuned OOF if needed\n",
        "y_tuned = globals().get(\"y_oof_tuned\", globals().get(\"y_oof\", None))\n",
        "p_tuned = globals().get(\"p_oof_tuned\", globals().get(\"p_oof\", None))\n",
        "t_tuned = globals().get(\"t_best_tuned\", globals().get(\"t_best\", 0.5))\n",
        "\n",
        "print(\"\\n=== OOF metrics comparison ===\")\n",
        "if y_base is not None and p_base is not None:\n",
        "    base_05 = oof_scores(y_base, p_base, 0.5)\n",
        "    base_bt = oof_scores(y_base, p_base, t_base)\n",
        "    print(\"Baseline @0.5:\", base_05, \"\\nBaseline @best:\", base_bt)\n",
        "else:\n",
        "    print(\"Baseline OOF: not found\")\n",
        "\n",
        "if y_tuned is not None and p_tuned is not None:\n",
        "    tuned_05 = oof_scores(y_tuned, p_tuned, 0.5)\n",
        "    tuned_bt = oof_scores(y_tuned, p_tuned, t_tuned)\n",
        "    print(\"Tuned    @0.5:\", tuned_05, \"\\nTuned    @best:\", tuned_bt)\n",
        "else:\n",
        "    print(\"Tuned OOF: not found\")\n"
      ],
      "metadata": {
        "id": "yR2aWgh66Iuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optuna tuning scaffold**\n",
        "\n",
        "\n",
        " Optimizes XGBoost hyperparameters against mean PR-AUC across folds (good for imbalance), with optional calibration during tuning (off by default to keep it fast). After tuning, it refits the walk-forward with calibration ON using the best params and recomputes OOF metrics."
      ],
      "metadata": {
        "id": "ZGdusBFn5fvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.1. Install/import Optuna + tuning config**"
      ],
      "metadata": {
        "id": "rvKrSJh15t7p"
      }
    },
    {
      "source": [
        "# !pip install --quiet optuna"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pFpggj7K59lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.0 — Install Optuna (one-time)\n",
        "import sys, subprocess, pkgutil\n",
        "if pkgutil.find_loader(\"optuna\") is None:\n",
        "    print(\"Installing optuna…\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"optuna\"])\n",
        "import optuna\n",
        "print(\"optuna version:\", optuna.__version__)\n"
      ],
      "metadata": {
        "id": "FM6N4Yns8QX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.2 (persistent) — Objective + study.optimize (SQLite) with fallback defaults ---\n",
        "\n",
        "# Fallbacks if 11.1 wasn't run in this kernel\n",
        "OPT_METRIC = globals().get(\"OPT_METRIC\", \"pr_auc\")\n",
        "N_TRIALS = int(globals().get(\"N_TRIALS\", 25))\n",
        "CALIBRATE_DURING_TUNING = bool(globals().get(\"CALIBRATE_DURING_TUNING\", False))\n",
        "STUDY_NAME = globals().get(\"STUDY_NAME\", \"xgb_fractal_walkforward\")\n",
        "\n",
        "import os, numpy as np, pandas as pd\n",
        "import optuna\n",
        "from typing import Dict, Any\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Guards\n",
        "assert 'forward_splits' in globals(), \"Run Section 7.1 first (forward_splits).\"\n",
        "assert 'evaluate_probs' in globals(), \"Run Section 7.1 first (evaluate_probs).\"\n",
        "assert 'X_final' in globals() and 'y_final' in globals(), \"Run Sections 6–7 first to build X_final/y_final.\"\n",
        "assert 'NUM_TRAIN' in globals() and 'NUM_TEST' in globals() and 'GAP' in globals(), \"Run Section 7.1 first.\"\n",
        "\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "def make_xgb(params: Dict[str, Any]) -> XGBClassifier:\n",
        "    return XGBClassifier(\n",
        "        n_estimators      = params[\"n_estimators\"],\n",
        "        max_depth         = params[\"max_depth\"],\n",
        "        learning_rate     = params[\"learning_rate\"],\n",
        "        subsample         = params[\"subsample\"],\n",
        "        colsample_bytree  = params[\"colsample_bytree\"],\n",
        "        min_child_weight  = params[\"min_child_weight\"],\n",
        "        gamma             = params[\"gamma\"],\n",
        "        reg_lambda        = params[\"reg_lambda\"],\n",
        "        reg_alpha         = params[\"reg_alpha\"],\n",
        "        tree_method       = \"hist\",\n",
        "        random_state      = 42,\n",
        "        n_jobs            = -1,\n",
        "        # scale_pos_weight set per-fold below\n",
        "    )\n",
        "\n",
        "def make_pipeline_for_trial(base_estimator, calibrate: bool) -> Pipeline:\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[(\"num\", StandardScaler(), numeric_cols)],\n",
        "        remainder=\"drop\",\n",
        "        verbose_feature_names_out=False\n",
        "    )\n",
        "    if calibrate:\n",
        "        clf = CalibratedClassifierCV(base_estimator=base_estimator, cv=3, method=\"sigmoid\")\n",
        "        return Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
        "    else:\n",
        "        return Pipeline([(\"prep\", pre), (\"clf\", base_estimator)])\n",
        "\n",
        "def trial_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"n_estimators\"     : trial.suggest_int(\"n_estimators\", 300, 1200, step=100),\n",
        "        \"max_depth\"        : trial.suggest_int(\"max_depth\", 2, 8),\n",
        "        \"learning_rate\"    : trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
        "        \"subsample\"        : trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"min_child_weight\" : trial.suggest_float(\"min_child_weight\", 1.0, 20.0),\n",
        "        \"gamma\"            : trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"reg_lambda\"       : trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"reg_alpha\"        : trial.suggest_float(\"reg_alpha\", 1e-3, 5.0, log=True),\n",
        "    }\n",
        "\n",
        "def objective(trial: optuna.Trial) -> float:\n",
        "    params = trial_params(trial)\n",
        "    fold_scores = []\n",
        "    step = 0\n",
        "\n",
        "    for tr, te in forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP):\n",
        "        X_tr, y_tr = X_final.iloc[tr], y_final.iloc[tr]\n",
        "        X_te, y_te = X_final.iloc[te], y_final.iloc[te]\n",
        "\n",
        "        pos = int(y_tr.sum()); neg = int(len(y_tr) - pos)\n",
        "        spw = (neg / pos) if pos > 0 else 1.0\n",
        "\n",
        "        est = make_xgb(params); est.set_params(scale_pos_weight=spw)\n",
        "        pipe = make_pipeline_for_trial(est, calibrate=CALIBRATE_DURING_TUNING)\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "\n",
        "        if CALIBRATE_DURING_TUNING:\n",
        "            p = pipe.predict_proba(X_te)[:, 1]\n",
        "        else:\n",
        "            X_te_t = pipe.named_steps[\"prep\"].transform(X_te)\n",
        "            p = pipe.named_steps[\"clf\"].predict_proba(X_te_t)[:, 1]\n",
        "\n",
        "        m = evaluate_probs(y_te.values, p, thr=0.5)\n",
        "        fold_scores.append(m[OPT_METRIC])\n",
        "\n",
        "        step += 1\n",
        "        trial.report(float(np.mean(fold_scores)), step=step)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return float(np.mean(fold_scores))\n",
        "\n",
        "# Persistent study\n",
        "os.makedirs(\"artifacts/optuna\", exist_ok=True)\n",
        "storage_uri = \"sqlite:///artifacts/optuna/study.db\"\n",
        "study = optuna.create_study(\n",
        "    study_name=STUDY_NAME,\n",
        "    direction=\"maximize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=2),\n",
        "    storage=storage_uri,\n",
        "    load_if_exists=True,\n",
        ")\n",
        "\n",
        "print(\"Starting optimization...\")\n",
        "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
        "print(\"Best value:\", study.best_value)\n",
        "print(\"Best params:\", study.best_params)\n"
      ],
      "metadata": {
        "id": "2htq5xef8nVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.2a. Pre-flight for 11.2 (MCC-focused tuning)**"
      ],
      "metadata": {
        "id": "_EvZoNc2I1Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-flight for 11.2 (MCC-focused tuning)\n",
        "needed = [\"forward_splits\",\"evaluate_probs\",\"X_final\",\"y_final\",\"NUM_TRAIN\",\"NUM_TEST\",\"GAP\"]\n",
        "missing = [n for n in needed if n not in globals()]\n",
        "print(\"Missing:\", missing if missing else \"None — good to go.\")\n",
        "try:\n",
        "    import optuna, xgboost\n",
        "    print(\"optuna OK,\", \"xgboost OK\")\n",
        "except Exception as e:\n",
        "    print(\"Import error:\", e)\n"
      ],
      "metadata": {
        "id": "TA2vGg52I3pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.2b. MCC-focused objective with per-fold validation threshold (SQLite study)**"
      ],
      "metadata": {
        "id": "jWO5iUBGIH4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.2 (replace) — Optuna objective optimizing test MCC with a val-chosen threshold ---\n",
        "\n",
        "# Fallbacks if 11.1 wasn't run\n",
        "OPT_METRIC = \"mcc\"\n",
        "N_TRIALS = int(globals().get(\"N_TRIALS\", 25))\n",
        "CALIBRATE_DURING_TUNING = bool(globals().get(\"CALIBRATE_DURING_TUNING\", False))\n",
        "STUDY_NAME = globals().get(\"STUDY_NAME\", \"xgb_fractal_walkforward\")\n",
        "\n",
        "import os, numpy as np, pandas as pd, optuna\n",
        "from typing import Dict, Any, Tuple\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import matthews_corrcoef, average_precision_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Guards (from Sections 6–7)\n",
        "assert 'forward_splits' in globals() and 'evaluate_probs' in globals(), \"Run Section 7.1 first.\"\n",
        "assert 'X_final' in globals() and 'y_final' in globals(), \"Run Sections 6–7 first.\"\n",
        "assert 'NUM_TRAIN' in globals() and 'NUM_TEST' in globals() and 'GAP' in globals(), \"Run Section 7.1 first.\"\n",
        "\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "def split_train_val(X: pd.DataFrame, y: pd.Series, val_frac: float = 0.15) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
        "    \"\"\"Time-ordered split: last val_frac of the training window is validation.\"\"\"\n",
        "    n = len(X)\n",
        "    v = max(50, int(n * val_frac))  # at least 50 rows for stability\n",
        "    v = min(v, n-1)\n",
        "    return X.iloc[:n-v], y.iloc[:n-v], X.iloc[n-v:], y.iloc[n-v:]\n",
        "\n",
        "def best_thr_mcc(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_v = 0.5, -np.inf\n",
        "    for t in grid:\n",
        "        v = matthews_corrcoef(y, (p >= t).astype(int))\n",
        "        if v > best_v:\n",
        "            best_t, best_v = float(t), float(v)\n",
        "    return best_t\n",
        "\n",
        "def make_xgb(params: Dict[str, Any]) -> XGBClassifier:\n",
        "    return XGBClassifier(\n",
        "        n_estimators     = params[\"n_estimators\"],\n",
        "        max_depth        = params[\"max_depth\"],\n",
        "        learning_rate    = params[\"learning_rate\"],\n",
        "        subsample        = params[\"subsample\"],\n",
        "        colsample_bytree = params[\"colsample_bytree\"],\n",
        "        min_child_weight = params[\"min_child_weight\"],\n",
        "        gamma            = params[\"gamma\"],\n",
        "        reg_lambda       = params[\"reg_lambda\"],\n",
        "        reg_alpha        = params[\"reg_alpha\"],\n",
        "        tree_method      = \"hist\",\n",
        "        random_state     = 42,\n",
        "        n_jobs           = -1,\n",
        "        # scale_pos_weight set per-fold below\n",
        "    )\n",
        "\n",
        "def make_pipeline(base_estimator, calibrate: bool) -> Pipeline:\n",
        "    pre = ColumnTransformer([(\"num\", StandardScaler(), numeric_cols)], remainder=\"drop\", verbose_feature_names_out=False)\n",
        "    if calibrate:\n",
        "        clf = CalibratedClassifierCV(base_estimator=base_estimator, cv=3, method=\"sigmoid\")\n",
        "        return Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
        "    else:\n",
        "        return Pipeline([(\"prep\", pre), (\"clf\", base_estimator)])\n",
        "\n",
        "def trial_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"n_estimators\"     : trial.suggest_int(\"n_estimators\", 300, 1200, step=100),\n",
        "        \"max_depth\"        : trial.suggest_int(\"max_depth\", 2, 8),\n",
        "        \"learning_rate\"    : trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
        "        \"subsample\"        : trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "        \"min_child_weight\" : trial.suggest_float(\"min_child_weight\", 1.0, 20.0),\n",
        "        \"gamma\"            : trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"reg_lambda\"       : trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"reg_alpha\"        : trial.suggest_float(\"reg_alpha\", 1e-3, 5.0, log=True),\n",
        "    }\n",
        "\n",
        "def objective(trial: optuna.Trial) -> float:\n",
        "    params = trial_params(trial)\n",
        "    fold_mcc = []\n",
        "    step = 0\n",
        "\n",
        "    for tr, te in forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP):\n",
        "        X_tr_full, y_tr_full = X_final.iloc[tr], y_final.iloc[tr]\n",
        "        X_te, y_te = X_final.iloc[te], y_final.iloc[te]\n",
        "\n",
        "        # Train/val split within the training window (no shuffling)\n",
        "        X_tr, y_tr, X_va, y_va = split_train_val(X_tr_full, y_tr_full, val_frac=0.15)\n",
        "\n",
        "        # class imbalance from training chunk\n",
        "        pos = int(y_tr.sum()); neg = int(len(y_tr) - pos)\n",
        "        spw = (neg / pos) if pos > 0 else 1.0\n",
        "\n",
        "        est = make_xgb(params); est.set_params(scale_pos_weight=spw)\n",
        "        pipe = make_pipeline(est, calibrate=CALIBRATE_DURING_TUNING)\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "\n",
        "        # Get probabilities on validation to choose threshold\n",
        "        if CALIBRATE_DURING_TUNING:\n",
        "            p_va = pipe.predict_proba(X_va)[:, 1]\n",
        "            p_te = pipe.predict_proba(X_te)[:, 1]\n",
        "        else:\n",
        "            X_va_t = pipe.named_steps[\"prep\"].transform(X_va)\n",
        "            X_te_t = pipe.named_steps[\"prep\"].transform(X_te)\n",
        "            p_va = pipe.named_steps[\"clf\"].predict_proba(X_va_t)[:, 1]\n",
        "            p_te = pipe.named_steps[\"clf\"].predict_proba(X_te_t)[:, 1]\n",
        "\n",
        "        t_val = best_thr_mcc(y_va.values, p_va)\n",
        "        mcc_te = matthews_corrcoef(y_te.values, (p_te >= t_val).astype(int))\n",
        "        fold_mcc.append(float(mcc_te))\n",
        "\n",
        "        # Optional: prune using running average MCC\n",
        "        step += 1\n",
        "        trial.report(np.mean(fold_mcc), step=step)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return float(np.mean(fold_mcc))\n",
        "\n",
        "# Persistent study (SQLite)\n",
        "os.makedirs(\"artifacts/optuna\", exist_ok=True)\n",
        "storage_uri = \"sqlite:///artifacts/optuna/study.db\"\n",
        "study = optuna.create_study(\n",
        "    study_name=STUDY_NAME,\n",
        "    direction=\"maximize\",\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=2),\n",
        "    storage=storage_uri,\n",
        "    load_if_exists=True,\n",
        ")\n",
        "\n",
        "print(\"Starting MCC-focused optimization…\")\n",
        "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
        "print(\"Best mean test MCC:\", study.best_value)\n",
        "print(\"Best params:\", study.best_params)\n"
      ],
      "metadata": {
        "id": "OwY7mDsFIOq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.3a. Refit with best params + calibration; choose per-fold validation thresholds**"
      ],
      "metadata": {
        "id": "spSVlxJ-JkBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.3a Refit with best params + calibration; per-fold validation thresholds ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Guards\n",
        "assert 'study' in globals(), \"Run Section 11.2 first to create `study` and find best params.\"\n",
        "assert 'make_xgb' in globals() and 'split_train_val' in globals() and 'best_thr_mcc' in globals(), \"Run Section 11.2 first.\"\n",
        "assert 'forward_splits' in globals() and 'evaluate_probs' in globals(), \"Run Section 7.1 first.\"\n",
        "assert 'X_final' in globals() and 'y_final' in globals(), \"Run Section 6 first.\"\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "\n",
        "# Calibration method for this final refit\n",
        "CALIB_METHOD_TUNED = globals().get(\"CALIB_METHOD_TUNED\", \"sigmoid\")  # 'sigmoid' or 'isotonic'\n",
        "\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "def make_calibrated_pipeline(best_params, spw: float, method: str = \"sigmoid\") -> Pipeline:\n",
        "    est = make_xgb(best_params)\n",
        "    est.set_params(scale_pos_weight=spw)\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=[(\"num\", StandardScaler(), numeric_cols)],\n",
        "        remainder=\"drop\",\n",
        "        verbose_feature_names_out=False\n",
        "    )\n",
        "    # Correct parameter name from base_estimator to estimator\n",
        "    clf = CalibratedClassifierCV(estimator=est, cv=3, method=method)\n",
        "    return Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
        "\n",
        "# Storage for out-of-fold results\n",
        "oof_probs_cal = np.full(len(y_final), np.nan, dtype=float)   # calibrated test probabilities\n",
        "oof_preds_valthr = np.full(len(y_final), np.nan, dtype=float)  # test preds using per-fold val-chosen threshold\n",
        "per_fold_thresholds = []\n",
        "fold_rows = []\n",
        "fold_id = 0\n",
        "\n",
        "for tr, te in forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP):\n",
        "    fold_id += 1\n",
        "    X_tr_full, y_tr_full = X_final.iloc[tr], y_final.iloc[tr]\n",
        "    X_te, y_te = X_final.iloc[te], y_final.iloc[te]\n",
        "\n",
        "    # time-ordered split inside training window\n",
        "    X_tr, y_tr, X_va, y_va = split_train_val(X_tr_full, y_tr_full, val_frac=0.15)\n",
        "\n",
        "    # imbalance handling\n",
        "    pos = int(y_tr.sum()); neg = int(len(y_tr) - pos)\n",
        "    spw = (neg / pos) if pos > 0 else 1.0\n",
        "\n",
        "    model = make_calibrated_pipeline(best_params, spw, method=CALIB_METHOD_TUNED)\n",
        "    model.fit(X_tr, y_tr)\n",
        "\n",
        "    # calibrated proba\n",
        "    p_va = model.predict_proba(X_va)[:, 1]\n",
        "    p_te = model.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    # pick threshold on validation, then apply to test\n",
        "    t_val = best_thr_mcc(y_va.values, p_va)\n",
        "    yhat_te_valthr = (p_te >= t_val).astype(int)\n",
        "\n",
        "    # store OOF outputs\n",
        "    oof_probs_cal[te] = p_te\n",
        "    oof_preds_valthr[te] = yhat_te_valthr\n",
        "    per_fold_thresholds.append({\"fold\": fold_id, \"thr_val\": float(t_val)})\n",
        "\n",
        "    # metrics at default 0.5 AND at per-fold val threshold\n",
        "    m_05   = evaluate_probs(y_te.values, p_te, thr=0.5)\n",
        "    m_val  = evaluate_probs(y_te.values, p_te, thr=t_val)\n",
        "    fold_rows.append({\n",
        "        \"fold\": fold_id,\n",
        "        \"n_train\": int(len(y_tr_full)), \"n_test\": int(len(y_te)),\n",
        "        \"pos_rate_train\": float(y_tr_full.mean()), \"pos_rate_test\": float(y_te.mean()),\n",
        "        \"thr_val\": float(t_val),\n",
        "        # default 0.5 metrics\n",
        "        \"roc_auc@0.5\": m_05[\"roc_auc\"], \"pr_auc@0.5\": m_05[\"pr_auc\"],\n",
        "        \"brier@0.5\": m_05[\"brier\"], \"mcc@0.5\": m_05[\"mcc\"],\n",
        "        # metrics when using the val-chosen threshold\n",
        "        \"roc_auc@val\": m_val[\"roc_auc\"], \"pr_auc@val\": m_val[\"pr_auc\"],\n",
        "        \"brier@val\": m_val[\"brier\"], \"mcc@val\": m_val[\"mcc\"],\n",
        "    })\n",
        "\n",
        "fold_metrics_valthr = pd.DataFrame(fold_rows)\n",
        "thr_table = pd.DataFrame(per_fold_thresholds)\n",
        "\n",
        "print(\"Per-fold metrics:\\n(thr=0.5 vs. thr chosen on validation)\")\n",
        "display(fold_metrics_valthr)\n",
        "print(\"\\nPer-fold validation-chosen thresholds:\")\n",
        "display(thr_table)\n",
        "print(\"\\nAverages (± std) using val-chosen thresholds:\")\n",
        "display(fold_metrics_valthr[[\"roc_auc@val\",\"pr_auc@val\",\"brier@val\",\"mcc@val\"]].agg(['mean','std']).round(4))"
      ],
      "metadata": {
        "id": "09XdeBLsJs3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. Pick best band & min-hold, apply to signals, plot, and stash decision config**"
      ],
      "metadata": {
        "id": "obpnu4k3AhkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.3b OOF aggregation, global best threshold, and artifacts ---\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Aggregate OOF\n",
        "mask = ~np.isnan(oof_probs_cal)\n",
        "y_oof_new = y_final.values[mask]\n",
        "p_oof_new = oof_probs_cal[mask]\n",
        "yhat_oof_valthr = oof_preds_valthr[mask].astype(int)\n",
        "\n",
        "print(f\"OOF coverage (calibrated): {mask.sum()} / {len(y_final)}\")\n",
        "\n",
        "# Metrics at thr=0.5 on OOF probabilities\n",
        "scores_05 = evaluate_probs(y_oof_new, p_oof_new, thr=0.5)\n",
        "print(\"\\nOOF metrics @0.5:\", {k: round(v, 4) for k, v in scores_05.items()})\n",
        "\n",
        "# Global best threshold on OOF probabilities (for comparison & plotting)\n",
        "def best_threshold(y_true: np.ndarray, p: np.ndarray, metric: str = \"mcc\"):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_v = 0.5, -np.inf\n",
        "    for t in grid:\n",
        "        v = matthews_corrcoef(y_true, (p >= t).astype(int))\n",
        "        if v > best_v:\n",
        "            best_t, best_v = float(t), float(v)\n",
        "    return best_t, best_v\n",
        "\n",
        "t_best_cal, m_best_cal = best_threshold(y_oof_new, p_oof_new, metric=\"mcc\")\n",
        "scores_best = evaluate_probs(y_oof_new, p_oof_new, thr=t_best_cal)\n",
        "print(f\"Best threshold on OOF (global): {t_best_cal:.3f}  (MCC={m_best_cal:.4f})\")\n",
        "print(\"OOF metrics @best:\", {k: round(v, 4) for k, v in scores_best.items()})\n",
        "\n",
        "# MCC when using per-fold validation thresholds (no single global threshold)\n",
        "mcc_valthr = float(matthews_corrcoef(y_oof_new, yhat_oof_valthr))\n",
        "print(f\"\\nOOF MCC using per-fold validation thresholds: {mcc_valthr:.4f}\")\n",
        "\n",
        "# Update globals so Sections 8–10 reuse the tuned, calibrated outputs\n",
        "p_oof = p_oof_new\n",
        "y_oof = y_oof_new\n",
        "t_best = t_best_cal\n",
        "m_best = m_best_cal\n",
        "oof_df = pd.DataFrame({\n",
        "    DATE_COL: df_all[DATE_COL].values[mask],\n",
        "    \"y_true\": y_oof_new,\n",
        "    \"p_hat\":  p_oof_new\n",
        "})\n",
        "fold_metrics = fold_metrics_valthr  # replace with the new per-fold table\n",
        "\n",
        "# Save artifacts\n",
        "import os, json\n",
        "os.makedirs(\"artifacts/tuned_mcc_valthr\", exist_ok=True)\n",
        "fold_metrics.to_csv(\"artifacts/tuned_mcc_valthr/fold_metrics_valthr.csv\", index=False)\n",
        "thr_table.to_csv(\"artifacts/tuned_mcc_valthr/per_fold_thresholds.csv\", index=False)\n",
        "oof_df.to_csv(\"artifacts/tuned_mcc_valthr/oof_predictions_calibrated.csv\", index=False)\n",
        "with open(\"artifacts/tuned_mcc_valthr/oof_summary.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"oof_at_0p5\": {k: round(float(v),4) for k,v in scores_05.items()},\n",
        "        \"oof_at_best\": {k: round(float(v),4) for k,v in scores_best.items()},\n",
        "        \"best_threshold_global\": float(t_best_cal),\n",
        "        \"mcc_oof_per_fold_val_thresholds\": float(mcc_valthr)\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved artifacts in artifacts/tuned_mcc_valthr/\")\n"
      ],
      "metadata": {
        "id": "lQW8Z7QXKbKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.4. One-shot summary**"
      ],
      "metadata": {
        "id": "6U9YZf3WNWY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.S — One-shot summary of tuning & refit results\n",
        "import json, numpy as np, pandas as pd\n",
        "\n",
        "def rfloat(x, nd=4):\n",
        "    try:\n",
        "        xf = float(x)\n",
        "        if np.isfinite(xf):\n",
        "            return round(xf, nd)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "summary = {}\n",
        "\n",
        "# 11.2 — optuna\n",
        "if 'study' in globals():\n",
        "    summary[\"optuna_best_mean_test_MCC\"] = rfloat(study.best_value)\n",
        "    summary[\"optuna_best_params\"] = study.best_params\n",
        "\n",
        "# 11.3a — per-fold metrics using validation-chosen thresholds\n",
        "if 'fold_metrics_valthr' in globals():\n",
        "    cols = [\"roc_auc@val\",\"pr_auc@val\",\"brier@val\",\"mcc@val\"]\n",
        "    agg = fold_metrics_valthr[cols].agg(['mean','std']).round(4)\n",
        "    summary[\"fold_metrics_valthr\"] = agg.to_dict()\n",
        "if 'thr_table' in globals():\n",
        "    summary[\"per_fold_thresholds_head\"] = thr_table.head(10).to_dict(orient=\"records\")\n",
        "\n",
        "# 11.3b — OOF aggregation\n",
        "if 'scores_05' in globals():\n",
        "    summary[\"oof_at_0p5\"] = {k: rfloat(v) for k,v in scores_05.items()}\n",
        "if 'scores_best' in globals() and 't_best_cal' in globals():\n",
        "    sb = {k: rfloat(v) for k,v in scores_best.items()}\n",
        "    sb[\"t_best\"] = rfloat(t_best_cal, 3)\n",
        "    summary[\"oof_at_best_global_thr\"] = sb\n",
        "if 'mcc_valthr' in globals():\n",
        "    summary[\"oof_mcc_per_fold_valthr\"] = rfloat(mcc_valthr)\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n"
      ],
      "metadata": {
        "id": "LbGNg7RiNpJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.3a′ Refit with prefit calibration on the validation slice (or raw )**"
      ],
      "metadata": {
        "id": "HtIZnn8-Os5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.3a′ Refit w/ best params + PREFIT calibration on the validation slice (or raw if you prefer) ---\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "assert 'study' in globals() and 'make_xgb' in globals() and 'split_train_val' in globals()\n",
        "assert 'forward_splits' in globals() and 'X_final' in globals() and 'y_final' in globals()\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "def make_raw_pipeline(spw: float) -> Pipeline:\n",
        "    est = make_xgb(best_params); est.set_params(scale_pos_weight=spw)\n",
        "    pre = ColumnTransformer([(\"num\", StandardScaler(), numeric_cols)], remainder=\"drop\", verbose_feature_names_out=False)\n",
        "    return Pipeline([(\"prep\", pre), (\"clf\", est)])\n",
        "\n",
        "CALIB_METHOD_PREFIT = \"isotonic\"  # try \"isotonic\" if val size is decent; else \"sigmoid\"\n",
        "\n",
        "oof_prob_raw = np.full(len(y_final), np.nan)   # raw (no calibration)\n",
        "oof_prob_cal = np.full(len(y_final), np.nan)   # calibrated via prefit on val\n",
        "oof_pred_valthr = np.full(len(y_final), np.nan)\n",
        "per_fold_rows = []\n",
        "per_fold_thr = []\n",
        "\n",
        "fold_id = 0\n",
        "for tr, te in forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP):\n",
        "    fold_id += 1\n",
        "    X_tr_full, y_tr_full = X_final.iloc[tr], y_final.iloc[tr]\n",
        "    X_te, y_te = X_final.iloc[te], y_final.iloc[te]\n",
        "    X_tr, y_tr, X_va, y_va = split_train_val(X_tr_full, y_tr_full, val_frac=0.15)\n",
        "\n",
        "    pos = int(y_tr.sum()); neg = int(len(y_tr) - pos)\n",
        "    spw = (neg / pos) if pos > 0 else 1.0\n",
        "\n",
        "    # Fit base model on training (no calibration)\n",
        "    pipe_raw = make_raw_pipeline(spw)\n",
        "    pipe_raw.fit(X_tr, y_tr)\n",
        "\n",
        "    # Raw probs\n",
        "    p_va_raw = pipe_raw.predict_proba(X_va)[:,1]\n",
        "    p_te_raw = pipe_raw.predict_proba(X_te)[:,1]\n",
        "\n",
        "    # Prefit calibration (fit calibrator ONLY on validation slice, no extra split)\n",
        "    calib = CalibratedClassifierCV(estimator=pipe_raw, cv='prefit', method=CALIB_METHOD_PREFIT)\n",
        "    calib.fit(X_va, y_va)  # learns mapping on val set\n",
        "\n",
        "    p_va_cal = calib.predict_proba(X_va)[:,1]\n",
        "    p_te_cal = calib.predict_proba(X_te)[:,1]\n",
        "\n",
        "    # Threshold chosen on validation **calibrated** probs (use calibrated probs end-to-end)\n",
        "    def best_thr_mcc(y, p):\n",
        "        grid = np.linspace(0.05, 0.95, 37)\n",
        "        t_best, m_best = 0.5, -np.inf\n",
        "        for t in grid:\n",
        "            m = matthews_corrcoef(y, (p>=t).astype(int))\n",
        "            if m > m_best:\n",
        "                t_best, m_best = float(t), float(m)\n",
        "        return t_best, m_best\n",
        "\n",
        "    t_val, _ = best_thr_mcc(y_va.values, p_va_cal)\n",
        "\n",
        "    # Store OOF\n",
        "    oof_prob_raw[te] = p_te_raw\n",
        "    oof_prob_cal[te] = p_te_cal\n",
        "    oof_pred_valthr[te] = (p_te_cal >= t_val).astype(int)\n",
        "    per_fold_thr.append({\"fold\": fold_id, \"thr_val\": float(t_val)})\n",
        "\n",
        "    # Per-fold metrics (optional quick view)\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "    def eval_probs(y,p,thr):\n",
        "        return dict(\n",
        "            roc_auc=float(roc_auc_score(y,p)),\n",
        "            pr_auc=float(average_precision_score(y,p)),\n",
        "            brier=float(brier_score_loss(y,p)),\n",
        "            mcc=float(matthews_corrcoef(y,(p>=thr).astype(int)))\n",
        "        )\n",
        "    per_fold_rows.append({\n",
        "        \"fold\": fold_id,\n",
        "        \"val_size\": int(len(y_va)),\n",
        "        \"test_size\": int(len(y_te)),\n",
        "        \"thr_val\": float(t_val),\n",
        "        **{f\"raw_{k}\":v for k,v in eval_probs(y_te, p_te_raw, t_val).items()},\n",
        "        **{f\"cal_{k}\":v for k,v in eval_probs(y_te, p_te_cal, t_val).items()},\n",
        "    })\n",
        "\n",
        "fold_prefit_tbl = pd.DataFrame(per_fold_rows)\n",
        "thr_table_prefit = pd.DataFrame(per_fold_thr)\n",
        "print(\"Per-fold (raw vs prefit-calibrated) test metrics using val-chosen threshold:\")\n",
        "display(fold_prefit_tbl.head(10))\n",
        "print(\"Val-chosen thresholds (prefit calib):\")\n",
        "display(thr_table_prefit.head(10))"
      ],
      "metadata": {
        "id": "r2nMI6FbOyJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.3b′. Refit Aggregate OOF (raw vs prefit-calibrated), get global best threshold, compare MCC**"
      ],
      "metadata": {
        "id": "a_NAaeKYPBKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.3b′ OOF aggregation: raw vs prefit-calibrated ---\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "mask_raw = ~np.isnan(oof_prob_raw)\n",
        "mask_cal = ~np.isnan(oof_prob_cal)\n",
        "assert mask_raw.sum() == mask_cal.sum()\n",
        "\n",
        "y_oof_raw = y_final.values[mask_raw]\n",
        "p_oof_raw = oof_prob_raw[mask_raw]\n",
        "y_oof_cal = y_final.values[mask_cal]\n",
        "p_oof_cal = oof_prob_cal[mask_cal]\n",
        "yhat_valthr = oof_pred_valthr[mask_cal].astype(int)\n",
        "\n",
        "def scores(y,p,thr):\n",
        "    return dict(\n",
        "        roc_auc = round(float(roc_auc_score(y,p)),4),\n",
        "        pr_auc  = round(float(average_precision_score(y,p)),4),\n",
        "        brier   = round(float(brier_score_loss(y,p)),5),\n",
        "        mcc     = round(float(matthews_corrcoef(y,(p>=thr).astype(int))),4),\n",
        "        thr     = round(float(thr),3)\n",
        "    )\n",
        "\n",
        "def best_thr(y,p):\n",
        "    grid = np.linspace(0.05,0.95,37)\n",
        "    best_t, best_m = 0.5, -1\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y,(p>=t).astype(int))\n",
        "        if m>best_m: best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "# Global thresholds\n",
        "t_raw, m_raw = best_thr(y_oof_raw, p_oof_raw)\n",
        "t_cal, m_cal = best_thr(y_oof_cal, p_oof_cal)\n",
        "\n",
        "print(\"OOF — RAW @best:\", scores(y_oof_raw, p_oof_raw, t_raw), \"| MCC:\", round(m_raw,4))\n",
        "print(\"OOF — CAL @best:\", scores(y_oof_cal, p_oof_cal, t_cal), \"| MCC:\", round(m_cal,4))\n",
        "print(\"OOF — CAL using per-fold val thresholds (no global thr): MCC =\", round(float(matthews_corrcoef(y_oof_cal, yhat_valthr)),4))\n",
        "\n",
        "# Update globals so Section 12 & 9 plots can reuse\n",
        "p_oof = p_oof_cal\n",
        "t_best = t_cal\n",
        "oof_df = pd.DataFrame({DATE_COL: df_all[DATE_COL].values[mask_cal], \"y_true\": y_oof_cal, \"p_hat\": p_oof_cal})\n",
        "fold_metrics = fold_prefit_tbl  # for quick display downstream\n",
        "thr_table = thr_table_prefit\n"
      ],
      "metadata": {
        "id": "6EGWonvwPM46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.3a″. Refit#2 with best params without calibration, choose thresholds on RAW validation**"
      ],
      "metadata": {
        "id": "b8oraxaPQ3Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.3a″ Refit with best params (RAW only), choose val thresholds on raw probs ---\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "assert 'study' in globals() and 'make_xgb' in globals() and 'split_train_val' in globals()\n",
        "assert 'forward_splits' in globals() and 'X_final' in globals() and 'y_final' in globals()\n",
        "assert 'NUM_TRAIN' in globals() and 'NUM_TEST' in globals() and 'GAP' in globals()\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "def make_raw_pipeline(spw: float) -> Pipeline:\n",
        "    est = make_xgb(best_params); est.set_params(scale_pos_weight=spw)\n",
        "    pre = ColumnTransformer([(\"num\", StandardScaler(), numeric_cols)], remainder=\"drop\", verbose_feature_names_out=False)\n",
        "    return Pipeline([(\"prep\", pre), (\"clf\", est)])\n",
        "\n",
        "def best_thr_mcc(y, p):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_m = 0.5, -np.inf\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y, (p>=t).astype(int))\n",
        "        if m > best_m:\n",
        "            best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "def eval_probs(y,p,thr):\n",
        "    return dict(\n",
        "        roc_auc=float(roc_auc_score(y,p)),\n",
        "        pr_auc=float(average_precision_score(y,p)),\n",
        "        brier=float(brier_score_loss(y,p)),\n",
        "        mcc=float(matthews_corrcoef(y,(p>=thr).astype(int)))\n",
        "    )\n",
        "\n",
        "oof_prob_raw2 = np.full(len(y_final), np.nan)\n",
        "oof_pred_valthr_raw = np.full(len(y_final), np.nan)\n",
        "thr_rows_raw, fold_rows_raw = [], []\n",
        "\n",
        "fold_id = 0\n",
        "for tr, te in forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP):\n",
        "    fold_id += 1\n",
        "    X_tr_full, y_tr_full = X_final.iloc[tr], y_final.iloc[tr]\n",
        "    X_te, y_te = X_final.iloc[te], y_final.iloc[te]\n",
        "    X_tr, y_tr, X_va, y_va = split_train_val(X_tr_full, y_tr_full, val_frac=0.15)\n",
        "\n",
        "    pos, neg = int(y_tr.sum()), int(len(y_tr)-int(y_tr.sum()))\n",
        "    spw = (neg/pos) if pos>0 else 1.0\n",
        "\n",
        "    pipe = make_raw_pipeline(spw).fit(X_tr, y_tr)\n",
        "\n",
        "    p_va = pipe.predict_proba(X_va)[:,1]\n",
        "    p_te = pipe.predict_proba(X_te)[:,1]\n",
        "\n",
        "    t_val, _ = best_thr_mcc(y_va.values, p_va)\n",
        "\n",
        "    oof_prob_raw2[te] = p_te\n",
        "    oof_pred_valthr_raw[te] = (p_te >= t_val).astype(int)\n",
        "    thr_rows_raw.append({\"fold\": fold_id, \"thr_val_raw\": float(t_val)})\n",
        "\n",
        "    m_05  = eval_probs(y_te.values, p_te, 0.5)\n",
        "    m_val = eval_probs(y_te.values, p_te, t_val)\n",
        "    fold_rows_raw.append({\n",
        "        \"fold\": fold_id, \"thr_val_raw\": t_val,\n",
        "        \"roc_auc@0.5\": m_05[\"roc_auc\"], \"pr_auc@0.5\": m_05[\"pr_auc\"], \"brier@0.5\": m_05[\"brier\"], \"mcc@0.5\": m_05[\"mcc\"],\n",
        "        \"roc_auc@val\": m_val[\"roc_auc\"], \"pr_auc@val\": m_val[\"pr_auc\"], \"brier@val\": m_val[\"brier\"], \"mcc@val\": m_val[\"mcc\"],\n",
        "    })\n",
        "\n",
        "fold_metrics_raw = pd.DataFrame(fold_rows_raw)\n",
        "thr_table_raw   = pd.DataFrame(thr_rows_raw)\n",
        "print(\"Per-fold metrics (RAW only):\")\n",
        "display(fold_metrics_raw)\n",
        "print(\"\\nPer-fold RAW validation-chosen thresholds:\")\n",
        "display(thr_table_raw.head(10))\n",
        "print(\"\\nAverages (± std) using RAW val-chosen thresholds:\")\n",
        "display(fold_metrics_raw[[\"roc_auc@val\",\"pr_auc@val\",\"brier@val\",\"mcc@val\"]].agg(['mean','std']).round(4))\n"
      ],
      "metadata": {
        "id": "dfnNJKrsRDp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **11.3b″. Aggregate RAW OOF, pick global best threshold, update globals & save**"
      ],
      "metadata": {
        "id": "sXmdCS1TRHf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11.3b″ Aggregate RAW OOF, compute global best threshold, save artifacts ---\n",
        "\n",
        "import numpy as np, pandas as pd, os, json\n",
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score, average_precision_score, brier_score_loss\n",
        "\n",
        "mask = ~np.isnan(oof_prob_raw2)\n",
        "y_oof_raw2 = y_final.values[mask]\n",
        "p_oof_raw2 = oof_prob_raw2[mask]\n",
        "yhat_valthr_raw = oof_pred_valthr_raw[mask].astype(int)\n",
        "\n",
        "def best_thr(y,p):\n",
        "    grid = np.linspace(0.05,0.95,37)\n",
        "    best_t, best_m = 0.5, -1\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y, (p>=t).astype(int))\n",
        "        if m>best_m: best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "def scores(y,p,thr):\n",
        "    return dict(\n",
        "        roc_auc = round(float(roc_auc_score(y,p)),4),\n",
        "        pr_auc  = round(float(average_precision_score(y,p)),4),\n",
        "        brier   = round(float(brier_score_loss(y,p)),5),\n",
        "        mcc     = round(float(matthews_corrcoef(y,(p>=thr).astype(int))),4),\n",
        "        thr     = round(float(thr),3)\n",
        "    )\n",
        "\n",
        "t_best_raw2, m_best_raw2 = best_thr(y_oof_raw2, p_oof_raw2)\n",
        "s_05  = scores(y_oof_raw2, p_oof_raw2, 0.5)\n",
        "s_best= scores(y_oof_raw2, p_oof_raw2, t_best_raw2)\n",
        "mcc_valthr_raw2 = float(matthews_corrcoef(y_oof_raw2, yhat_valthr_raw))\n",
        "\n",
        "print(\"OOF (RAW) @0.5:\", s_05)\n",
        "print(\"OOF (RAW) @best:\", s_best, \"| MCC:\", round(m_best_raw2,4))\n",
        "print(\"OOF (RAW) using per-fold RAW val thresholds: MCC =\", round(mcc_valthr_raw2,4))\n",
        "\n",
        "# Update globals so Sections 9 & 12 use RAW\n",
        "p_oof = p_oof_raw2\n",
        "y_oof = y_oof_raw2\n",
        "t_best = t_best_raw2\n",
        "m_best = m_best_raw2\n",
        "oof_df = pd.DataFrame({DATE_COL: df_all[DATE_COL].values[mask], \"y_true\": y_oof_raw2, \"p_hat\": p_oof_raw2})\n",
        "fold_metrics = fold_metrics_raw\n",
        "thr_table = thr_table_raw\n",
        "\n",
        "# Save artifacts\n",
        "os.makedirs(\"artifacts/raw_valthr\", exist_ok=True)\n",
        "fold_metrics.to_csv(\"artifacts/raw_valthr/fold_metrics_raw.csv\", index=False)\n",
        "thr_table.to_csv(\"artifacts/raw_valthr/per_fold_thresholds_raw.csv\", index=False)\n",
        "oof_df.to_csv(\"artifacts/raw_valthr/oof_predictions_raw.csv\", index=False)\n",
        "with open(\"artifacts/raw_valthr/oof_summary_raw.json\", \"w\") as f:\n",
        "    json.dump({\"oof_at_0p5\": s_05, \"oof_at_best\": s_best,\n",
        "               \"best_threshold_global\": float(t_best_raw2),\n",
        "               \"mcc_oof_per_fold_val_thresholds\": mcc_valthr_raw2}, f, indent=2)\n",
        "print(\"Saved artifacts to artifacts/raw_valthr/\")\n"
      ],
      "metadata": {
        "id": "34eGvmO9RQVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.1′ — Quick reliability check: RAW vs CAL (sanity plot + ECE)**"
      ],
      "metadata": {
        "id": "qoH0CrHLRV26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8.1′ Reliability: RAW vs CAL (if both available) ---\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "assert 'y_oof' in globals() and 'p_oof' in globals(), \"Run 11.3b″ to set RAW as current.\"\n",
        "y_raw, p_raw = y_oof, p_oof\n",
        "\n",
        "# If calibrated probs from earlier exist, compare; else plot RAW only\n",
        "y_cal = globals().get(\"y_oof_cal\", None)\n",
        "p_cal = globals().get(\"p_oof_cal\", None)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "prob_true_raw, prob_pred_raw = calibration_curve(y_raw, p_raw, n_bins=12, strategy=\"quantile\")\n",
        "plt.plot(prob_pred_raw, prob_true_raw, marker='o', label=\"RAW\")\n",
        "if y_cal is not None and p_cal is not None and len(y_cal)==len(p_cal):\n",
        "    prob_true_cal, prob_pred_cal = calibration_curve(y_cal, p_cal, n_bins=12, strategy=\"quantile\")\n",
        "    plt.plot(prob_pred_cal, prob_true_cal, marker='o', label=\"CAL\")\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"Predicted probability\")\n",
        "plt.ylabel(\"Empirical frequency\")\n",
        "plt.title(\"Reliability Diagram (OOF)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "ece_raw = float(np.mean(np.abs(prob_true_raw - prob_pred_raw)))\n",
        "print(f\"RAW ECE: {ece_raw:.4f}\")\n",
        "if y_cal is not None and p_cal is not None:\n",
        "    ece_cal = float(np.mean(np.abs(prob_true_cal - prob_pred_cal)))\n",
        "    print(f\"CAL ECE: {ece_cal:.4f}\")\n"
      ],
      "metadata": {
        "id": "-yofzzwqRkjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12.1. Helpers (fallback backtest + signals backtest)**"
      ],
      "metadata": {
        "id": "iZTlNPigEYPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 12.1 Backtest helpers for curves (global threshold & per-fold signals) ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fallback: stats helper (if not defined in Section 9)\n",
        "if 'performance_stats' not in globals():\n",
        "    def performance_stats(equity_curve, freq=252):\n",
        "        rets = np.log(equity_curve).diff().dropna()\n",
        "        ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "        ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "        sharpe = float(ann_ret / ann_vol) if ann_vol>0 else np.nan\n",
        "        peak = equity_curve.cummax()\n",
        "        dd = (equity_curve/peak - 1.0)\n",
        "        mdd = float(dd.min())\n",
        "        return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "# Fallback: global-threshold backtest (if Section 9's backtest_from_oof isn't present)\n",
        "if 'backtest_from_oof' not in globals():\n",
        "    def backtest_from_oof(oof_df, prices, t_best, tc_bps=5, mode=\"long_only\"):\n",
        "        df = oof_df.merge(prices[[DATE_COL, 'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "        df['r1'] = df['logret'].shift(-1)\n",
        "        df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "\n",
        "        if mode == \"long_only\":\n",
        "            df['pos'] = (df['p_hat'] >= t_best).astype(int)\n",
        "        elif mode == \"long_short\":\n",
        "            df['pos'] = 0\n",
        "            df.loc[df['p_hat'] >= t_best, 'pos'] = 1\n",
        "            df.loc[df['p_hat'] <= (1 - t_best), 'pos'] = -1\n",
        "        else:\n",
        "            raise ValueError(\"Unknown mode\")\n",
        "\n",
        "        df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "        df['turnover'] = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "        tc = (tc_bps / 1e4)\n",
        "        df['ret_strategy'] = df['pos_shift'] * df['r1'] - df['turnover'] * tc\n",
        "        df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "        return df, performance_stats(df['equity'])\n",
        "\n",
        "def backtest_from_signals(oof_dates, signals, prices, tc_bps=5):\n",
        "    \"\"\"\n",
        "    Backtest from *precomputed* signals (0/1 long-only).\n",
        "    signals: 1 = long, 0 = flat (same length as oof_dates)\n",
        "    \"\"\"\n",
        "    sig_df = pd.DataFrame({DATE_COL: oof_dates, \"signal\": signals.astype(int)})\n",
        "    df = sig_df.merge(prices[[DATE_COL, 'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "\n",
        "    df['pos_shift'] = df['signal'].shift(1).fillna(0)\n",
        "    df['turnover'] = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    tc = (tc_bps / 1e4)\n",
        "    df['ret_strategy'] = df['pos_shift'] * df['r1'] - df['turnover'] * tc\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    return df, performance_stats(df['equity'])\n"
      ],
      "metadata": {
        "id": "dDdzym1nEkv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12.3. PnL curves using RAW OOF (global & per-fold thresholds)**"
      ],
      "metadata": {
        "id": "k91gkt1MRyw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 12.4 Curves using RAW OOF (global thr & per-fold RAW thr) ---\n",
        "\n",
        "assert 'oof_df' in globals() and 't_best' in globals() and 'thr_table' in globals()\n",
        "assert 'prices' in globals() and 'logret' in prices.columns\n",
        "\n",
        "TC_BPS = globals().get(\"TC_BPS\", 5)\n",
        "\n",
        "# Global threshold (RAW)\n",
        "bt_raw_long, st_raw_long = backtest_from_oof(oof_df, prices, t_best=t_best, tc_bps=TC_BPS, mode=\"long_only\")\n",
        "bt_raw_ls,   st_raw_ls   = backtest_from_oof(oof_df, prices, t_best=t_best, tc_bps=TC_BPS, mode=\"long_short\")\n",
        "\n",
        "# Per-fold RAW thresholds → rebuild signals\n",
        "thr_per_idx = np.full(len(y_final), np.nan)\n",
        "for k, (tr, te) in enumerate(forward_splits(len(y_final), NUM_TRAIN, NUM_TEST, GAP), start=1):\n",
        "    if k-1 < len(thr_table):\n",
        "        thr_per_idx[te] = float(thr_table.iloc[k-1]['thr_val_raw'])\n",
        "mask = ~np.isnan(thr_per_idx)\n",
        "thr_oof = thr_per_idx[mask]\n",
        "\n",
        "signals_long = (oof_df[\"p_hat\"].values >= thr_oof).astype(int)\n",
        "signals_ls   = np.zeros_like(signals_long)\n",
        "signals_ls[oof_df[\"p_hat\"].values >= thr_oof] = 1\n",
        "signals_ls[oof_df[\"p_hat\"].values <= (1.0 - thr_oof)] = -1\n",
        "\n",
        "bt_val_long, st_val_long = backtest_from_signals(oof_df[DATE_COL].values, signals_long, prices, tc_bps=TC_BPS)\n",
        "bt_val_ls,   st_val_ls   = backtest_from_signals(oof_df[DATE_COL].values, signals_ls,   prices, tc_bps=TC_BPS)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(bt_raw_long[DATE_COL], bt_raw_long['equity'], label=\"RAW global thr (long-only)\")\n",
        "plt.plot(bt_raw_ls[DATE_COL],   bt_raw_ls['equity'],   label=\"RAW global thr (long/short)\")\n",
        "plt.plot(bt_val_long[DATE_COL], bt_val_long['equity'], label=\"RAW per-fold thr (long-only)\")\n",
        "plt.plot(bt_val_ls[DATE_COL],   bt_val_ls['equity'],   label=\"RAW per-fold thr (long/short)\")\n",
        "plt.title(\"Strategy Equity — RAW thresholds (OOF, with costs)\")\n",
        "plt.xlabel(DATE_COL); plt.ylabel(\"Equity (start=1.0)\")\n",
        "plt.grid(True, alpha=0.3); plt.legend(); plt.show()\n",
        "\n",
        "def _rs(d): return {k: round(v,4) for k,v in d.items()}\n",
        "print(f\"Stats (TC={TC_BPS} bps)\")\n",
        "print(\"RAW global — Long-only :\", _rs(st_raw_long))\n",
        "print(\"RAW global — Long/Short:\", _rs(st_raw_ls))\n",
        "print(\"RAW per-fold — Long    :\", _rs(st_val_long))\n",
        "print(\"RAW per-fold — L/S     :\", _rs(st_val_ls))\n"
      ],
      "metadata": {
        "id": "giCuDXFVR2J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12.5. Pick best band & min-hold, apply to signals, plot, and stash decision config**"
      ],
      "metadata": {
        "id": "31RzZ-4PBSf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 12.6 Choose best band & min-hold, apply & plot, stash config ---\n",
        "\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, os, json\n",
        "\n",
        "# Guards: needs RAW OOF from 11.3b″ and sweeper from 12.5 (or we'll run a default sweep)\n",
        "assert 'oof_df' in globals() and 'p_oof' in globals() and 't_best' in globals(), \"Run 11.3b″ first to set RAW OOF + t_best.\"\n",
        "assert 'prices' in globals() and 'logret' in prices.columns, \"Run 6.1 to build logret.\"\n",
        "TC_BPS = globals().get(\"TC_BPS\", 5)\n",
        "\n",
        "# --- helpers (reuse if not defined) ---\n",
        "def enforce_min_hold(signals: np.ndarray, min_hold: int) -> np.ndarray:\n",
        "    if min_hold <= 1: return signals.astype(int)\n",
        "    out = np.zeros_like(signals, dtype=int)\n",
        "    cur, hold = 0, 0\n",
        "    for i, s in enumerate(signals.astype(int)):\n",
        "        if s == cur:\n",
        "            hold += 1\n",
        "        else:\n",
        "            if hold >= min_hold:\n",
        "                cur = s\n",
        "                hold = 1\n",
        "            else:\n",
        "                hold += 1\n",
        "        out[i] = cur\n",
        "    return out\n",
        "\n",
        "def backtest_signals_with_hold(dates, signals, prices, tc_bps=5):\n",
        "    sig_df = pd.DataFrame({DATE_COL: dates, \"signal\": signals.astype(int)})\n",
        "    df = sig_df.merge(prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "    df['pos_shift'] = df['signal'].shift(1).fillna(0)\n",
        "    df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    tc = (tc_bps/1e4)\n",
        "    df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*tc\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    return df, performance_stats(df['equity'])\n",
        "\n",
        "def sweep_band_and_hold(oof_df, base_thr, prices, tc_bps=5, bands=(0.0,0.02,0.04,0.06,0.08,0.10), holds=(1,3,5,10)):\n",
        "    results = []\n",
        "    p = oof_df[\"p_hat\"].values\n",
        "    d = oof_df[DATE_COL].values\n",
        "    for b in bands:\n",
        "        tL = min(0.99, base_thr + b)\n",
        "        tS = max(0.01, 1.0 - base_thr - b)\n",
        "        long_sig = (p >= tL).astype(int)\n",
        "        ls_sig   = np.where(p >= tL, 1, np.where(p <= tS, -1, 0))\n",
        "        for h in holds:\n",
        "            _long = enforce_min_hold(long_sig, h)\n",
        "            _ls   = enforce_min_hold(ls_sig,   h)\n",
        "            _, stL = backtest_signals_with_hold(d, _long, prices, tc_bps=tc_bps)\n",
        "            _, stS = backtest_signals_with_hold(d, _ls,   prices, tc_bps=tc_bps)\n",
        "            results.append(dict(\n",
        "                band=b, min_hold=h,\n",
        "                thr_long=tL, thr_short=tS,\n",
        "                long_CAGR=stL['CAGR'], long_Sharpe=stL['Sharpe'], long_MaxDD=stL['MaxDD'],\n",
        "                ls_CAGR=stS['CAGR'],   ls_Sharpe=stS['Sharpe'],   ls_MaxDD=stS['MaxDD']\n",
        "            ))\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Use existing sweep grid if available, otherwise run a default sweep\n",
        "if 'grid' not in globals() or not isinstance(grid, pd.DataFrame) or grid.empty:\n",
        "    grid = sweep_band_and_hold(oof_df, base_thr=t_best, prices=prices, tc_bps=TC_BPS)\n",
        "\n",
        "# Selection rule: maximize long/short Sharpe, subject to a drawdown guard (e.g., MaxDD >= -35%)\n",
        "DD_GUARD = -0.35\n",
        "cand = grid.query(\"ls_MaxDD >= @DD_GUARD\").copy()\n",
        "if cand.empty:\n",
        "    cand = grid.copy()  # fall back if all violate the guard\n",
        "best = cand.sort_values([\"ls_Sharpe\",\"long_Sharpe\"], ascending=False).iloc[0]\n",
        "\n",
        "BAND   = float(best[\"band\"])\n",
        "MIN_H  = int(best[\"min_hold\"])\n",
        "THR_L  = float(best[\"thr_long\"])\n",
        "THR_S  = float(best[\"thr_short\"])\n",
        "\n",
        "print(\"Chosen decision settings:\",\n",
        "      {\"band\": BAND, \"min_hold\": MIN_H, \"thr_long\": round(THR_L,3), \"thr_short\": round(THR_S,3)})\n",
        "\n",
        "# Build signals using chosen params\n",
        "p = oof_df[\"p_hat\"].values\n",
        "d = oof_df[DATE_COL].values\n",
        "\n",
        "sig_long = enforce_min_hold((p >= THR_L).astype(int), MIN_H)\n",
        "sig_ls   = enforce_min_hold(np.where(p >= THR_L, 1, np.where(p <= THR_S, -1, 0)), MIN_H)\n",
        "\n",
        "bt_long, st_long = backtest_signals_with_hold(d, sig_long, prices, tc_bps=TC_BPS)\n",
        "bt_ls,   st_ls   = backtest_signals_with_hold(d, sig_ls,   prices, tc_bps=TC_BPS)\n",
        "\n",
        "# Plot vs previous RAW globals (if available)\n",
        "plt.figure(figsize=(7,4))\n",
        "if 'bt_raw_long' in globals(): plt.plot(bt_raw_long[DATE_COL], bt_raw_long['equity'], label=\"RAW global thr (long-only)\")\n",
        "if 'bt_raw_ls'   in globals(): plt.plot(bt_raw_ls[DATE_COL],   bt_raw_ls['equity'],   label=\"RAW global thr (long/short)\")\n",
        "plt.plot(bt_long[DATE_COL], bt_long['equity'], label=f\"Selected band={BAND:.2f}, hold={MIN_H} (long-only)\")\n",
        "plt.plot(bt_ls[DATE_COL],   bt_ls['equity'],   label=f\"Selected band={BAND:.2f}, hold={MIN_H} (long/short)\")\n",
        "plt.title(\"Equity with Selected Band & Min-Hold (OOF, with costs)\")\n",
        "plt.xlabel(DATE_COL); plt.ylabel(\"Equity (start=1.0)\")\n",
        "plt.grid(True, alpha=0.3); plt.legend(); plt.show()\n",
        "\n",
        "def _rs(d): return {k: round(v,4) for k,v in d.items()}\n",
        "print(f\"Stats (TC={TC_BPS} bps)\")\n",
        "print(\"Selected — Long-only :\", _rs(st_long))\n",
        "print(\"Selected — Long/Short:\", _rs(st_ls))\n",
        "\n",
        "# Stash a decision policy for Section 13\n",
        "DECISION_RULE = dict(\n",
        "    mode=\"long_short\",          # change to \"long_only\" if you prefer\n",
        "    base_threshold=float(t_best),\n",
        "    band=BAND,\n",
        "    min_hold=MIN_H,\n",
        "    thr_long=THR_L,\n",
        "    thr_short=THR_S,\n",
        "    tc_bps=TC_BPS\n",
        ")\n",
        "\n",
        "# Save a small artifact for reproducibility\n",
        "os.makedirs(\"artifacts/decision\", exist_ok=True)\n",
        "with open(\"artifacts/decision/selected_policy.json\",\"w\") as f:\n",
        "    json.dump(DECISION_RULE, f, indent=2)\n",
        "print(\"Saved decision policy → artifacts/decision/selected_policy.json\")\n"
      ],
      "metadata": {
        "id": "P7yDzXQ7BUM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13.1. Fit final model and save pipeline + config including decision policy**"
      ],
      "metadata": {
        "id": "h8vhN4lgEsel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 13.1 (updated) Final fit & save: model + config (with decision policy) ---\n",
        "\n",
        "import os, json, joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "assert 'study' in globals() and 'make_xgb' in globals()\n",
        "assert 'X_final' in globals() and 'y_final' in globals()\n",
        "assert 'DECISION_RULE' in globals(), \"Run 12.6 to set DECISION_RULE.\"\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "numeric_cols = list(X_final.columns)\n",
        "\n",
        "# class weight on full sample\n",
        "pos = int(y_final.sum()); neg = int(len(y_final) - pos)\n",
        "spw = (neg/pos) if pos>0 else 1.0\n",
        "\n",
        "est_final = make_xgb(best_params); est_final.set_params(scale_pos_weight=spw)\n",
        "pre = ColumnTransformer([(\"num\", StandardScaler(), numeric_cols)], remainder=\"drop\", verbose_feature_names_out=False)\n",
        "final_pipe = Pipeline([(\"prep\", pre), (\"clf\", est_final)])\n",
        "final_pipe.fit(X_final, y_final)\n",
        "\n",
        "os.makedirs(\"artifacts/final_model\", exist_ok=True)\n",
        "joblib.dump(final_pipe, \"artifacts/final_model/fractal_xgb_pipeline.joblib\")\n",
        "\n",
        "config = dict(\n",
        "    ticker=TICKER, start=START, end=END,\n",
        "    best_params=best_params, scale_pos_weight=float(spw),\n",
        "    features=numeric_cols, date_col=DATE_COL,\n",
        "    decision=DECISION_RULE  # includes mode, base_threshold, band, min_hold, thr_long, thr_short, tc_bps\n",
        ")\n",
        "with open(\"artifacts/final_model/config.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"Saved model → artifacts/final_model/fractal_xgb_pipeline.joblib\")\n",
        "print(\"Saved config → artifacts/final_model/config.json\")\n"
      ],
      "metadata": {
        "id": "ciHUTzd4ExoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13.2. Predict helper that respects the band (min-hold is enforced in your trading loop)**"
      ],
      "metadata": {
        "id": "xUJG2XifE4BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 13.2 (updated) Predict helper using saved model & decision policy ---\n",
        "import joblib, pandas as pd, json\n",
        "\n",
        "def load_final_model():\n",
        "    pipe = joblib.load(\"artifacts/final_model/fractal_xgb_pipeline.joblib\")\n",
        "    with open(\"artifacts/final_model/config.json\") as f:\n",
        "        cfg = json.load(f)\n",
        "    return pipe, cfg\n",
        "\n",
        "def predict_from_features_row(x_row: pd.Series):\n",
        "    \"\"\"\n",
        "    x_row: single-row Series/DataFrame with columns identical to X_final.columns\n",
        "    Decision: uses global banded thresholds. min_hold is *not* enforceable on a single row;\n",
        "              apply it in your live trading loop over time.\n",
        "    \"\"\"\n",
        "    pipe, cfg = load_final_model()\n",
        "    feats = cfg[\"features\"]\n",
        "    proba = float(pipe.predict_proba(pd.DataFrame([x_row[c] for c in feats]).T)[:,1][0])\n",
        "\n",
        "    rule = cfg[\"decision\"]\n",
        "    thr_long  = float(rule[\"thr_long\"])\n",
        "    thr_short = float(rule[\"thr_short\"])\n",
        "    mode = rule.get(\"mode\",\"long_short\")\n",
        "\n",
        "    if mode == \"long_only\":\n",
        "        decision = 1 if proba >= thr_long else 0\n",
        "    else:\n",
        "        decision = 1 if proba >= thr_long else (-1 if proba <= thr_short else 0)\n",
        "\n",
        "    return {\"prob\": proba, \"decision\": decision, \"thr_long\": thr_long, \"thr_short\": thr_short}\n"
      ],
      "metadata": {
        "id": "BfJsFQJ0E5zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14. Deployment smoke-test — reload model & do a quick predict**"
      ],
      "metadata": {
        "id": "gBePPxmmFp9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 14.1 Reload final model + config, run a quick predict ---\n",
        "\n",
        "import json, joblib, pandas as pd, numpy as np, os\n",
        "from pathlib import Path\n",
        "\n",
        "# Files from Sections 12.6 & 13.1 (updated)\n",
        "model_path  = Path(\"artifacts/final_model/fractal_xgb_pipeline.joblib\")\n",
        "config_path = Path(\"artifacts/final_model/config.json\")\n",
        "\n",
        "assert model_path.exists() and config_path.exists(), \"Run 13.1 (updated) to save the model & config.\"\n",
        "\n",
        "pipe = joblib.load(model_path)\n",
        "cfg  = json.load(open(config_path))\n",
        "feat_cols = cfg[\"features\"]\n",
        "rule = cfg[\"decision\"]\n",
        "\n",
        "# Take the most recent feature row and score it\n",
        "x_row = X_final.iloc[-1][feat_cols]\n",
        "proba = float(pipe.predict_proba(pd.DataFrame([x_row], columns=feat_cols))[:,1][0])\n",
        "\n",
        "# Apply banded thresholds (min_hold is enforced over time, not on a single row)\n",
        "thr_long  = float(rule[\"thr_long\"])\n",
        "thr_short = float(rule[\"thr_short\"])\n",
        "mode      = rule.get(\"mode\",\"long_short\")\n",
        "\n",
        "if mode == \"long_only\":\n",
        "    decision = 1 if proba >= thr_long else 0\n",
        "else:\n",
        "    decision = 1 if proba >= thr_long else (-1 if proba <= thr_short else 0)\n",
        "\n",
        "print({\n",
        "    \"prob\": round(proba,6),\n",
        "    \"mode\": mode,\n",
        "    \"thr_long\": thr_long,\n",
        "    \"thr_short\": thr_short,\n",
        "    \"one_step_decision\": int(decision)\n",
        "})\n"
      ],
      "metadata": {
        "id": "mhQEvs2UFr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15. Live scoring + trading helper (applies band and min-hold)**"
      ],
      "metadata": {
        "id": "ip5szzfTFwk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 15.1 Live trading loop using saved decision policy (band + min_hold) ---\n",
        "\n",
        "import json, joblib, pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reuse helpers if present; otherwise define lightweight versions\n",
        "if 'enforce_min_hold' not in globals():\n",
        "    def enforce_min_hold(signals: np.ndarray, min_hold: int) -> np.ndarray:\n",
        "        if min_hold <= 1: return signals.astype(int)\n",
        "        out = np.zeros_like(signals, dtype=int); cur, hold = 0, 0\n",
        "        for i, s in enumerate(signals.astype(int)):\n",
        "            if s == cur:\n",
        "                hold += 1\n",
        "            else:\n",
        "                if hold >= min_hold:\n",
        "                    cur = s; hold = 1\n",
        "                else:\n",
        "                    hold += 1\n",
        "            out[i] = cur\n",
        "        return out\n",
        "\n",
        "if 'backtest_signals_with_hold' not in globals():\n",
        "    def backtest_signals_with_hold(dates, signals, prices, tc_bps=5):\n",
        "        sig_df = pd.DataFrame({DATE_COL: dates, \"signal\": signals.astype(int)})\n",
        "        df = sig_df.merge(prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "        df['r1'] = df['logret'].shift(-1)\n",
        "        df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "        df['pos_shift'] = df['signal'].shift(1).fillna(0)\n",
        "        df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "        tc = (tc_bps/1e4)\n",
        "        df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*tc\n",
        "        df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "        return df, performance_stats(df['equity'])\n",
        "\n",
        "# Load model + policy\n",
        "pipe = joblib.load(\"artifacts/final_model/fractal_xgb_pipeline.joblib\")\n",
        "cfg  = json.load(open(\"artifacts/final_model/config.json\"))\n",
        "feat_cols = cfg[\"features\"]; rule = cfg[\"decision\"]\n",
        "mode = rule.get(\"mode\",\"long_short\"); min_hold = int(rule[\"min_hold\"])\n",
        "thr_long = float(rule[\"thr_long\"]); thr_short = float(rule[\"thr_short\"])\n",
        "tc_bps = int(rule.get(\"tc_bps\", 5))\n",
        "\n",
        "# Build a scoring frame (date + features). Here we reuse df_all/X_final; in prod, replace with your live feature feed.\n",
        "sc_df = df_all[[DATE_COL]].merge(X_final.reset_index(drop=True), left_index=True, right_index=True)\n",
        "sc_df = sc_df.sort_values(DATE_COL).reset_index(drop=True)\n",
        "\n",
        "# Predict probabilities\n",
        "probs = pipe.predict_proba(sc_df[feat_cols])[:,1]\n",
        "dates = sc_df[DATE_COL].values\n",
        "\n",
        "# Apply policy (band + min_hold)\n",
        "if mode == \"long_only\":\n",
        "    raw_sig = (probs >= thr_long).astype(int)\n",
        "else:\n",
        "    raw_sig = np.zeros_like(probs, dtype=int)\n",
        "    raw_sig[probs >= thr_long]  = 1\n",
        "    raw_sig[probs <= thr_short] = -1\n",
        "\n",
        "sig = enforce_min_hold(raw_sig, min_hold)\n",
        "\n",
        "# Backtest with costs\n",
        "bt, stats = backtest_signals_with_hold(dates, sig, prices, tc_bps=tc_bps)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(bt[DATE_COL], bt['equity'], label=f\"Live-loop policy ({mode}, band={rule['band']:.02f}, hold={min_hold})\")\n",
        "plt.title(\"Equity — Saved Policy (OOF period, with costs)\")\n",
        "plt.xlabel(DATE_COL); plt.ylabel(\"Equity (start=1.0)\")\n",
        "plt.grid(True, alpha=0.3); plt.legend(); plt.show()\n",
        "\n",
        "print(\"Policy:\", dict(mode=mode, thr_long=thr_long, thr_short=thr_short, min_hold=min_hold, tc_bps=tc_bps))\n",
        "print(\"Stats:\", {k: round(v,4) for k,v in stats.items()})\n"
      ],
      "metadata": {
        "id": "vQU9aVVBF5YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **16.1. Out-of-time holdout (train on early period, test on the last ~20%)**"
      ],
      "metadata": {
        "id": "fTgGkXkIJNqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 16.1 OOT holdout backtest with saved policy ---\n",
        "\n",
        "import numpy as np, pandas as pd, json, joblib, matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "assert 'df_all' in globals() and DATE_COL in df_all.columns\n",
        "assert 'X_final' in globals() and 'y_final' in globals()\n",
        "assert 'study' in globals() and 'make_xgb' in globals()\n",
        "assert 'DECISION_RULE' in globals() and 'prices' in globals() and 'logret' in prices.columns\n",
        "\n",
        "# choose split: last 20% as OOT test (or set a date with SPLIT_DATE=\"2022-01-01\")\n",
        "SPLIT_FRAC = 0.80\n",
        "split_idx = int(len(df_all) * SPLIT_FRAC)\n",
        "split_date = df_all[DATE_COL].iloc[split_idx]\n",
        "\n",
        "train_mask = df_all[DATE_COL] < split_date\n",
        "test_mask  = df_all[DATE_COL] >= split_date\n",
        "\n",
        "X_tr, y_tr = X_final[train_mask.values], y_final[train_mask.values]\n",
        "X_te       = X_final[test_mask.values]\n",
        "dates_te   = df_all.loc[test_mask, DATE_COL].values\n",
        "\n",
        "# class weight on training\n",
        "pos, neg = int(y_tr.sum()), int(len(y_tr)-int(y_tr.sum()))\n",
        "spw = (neg/pos) if pos>0 else 1.0\n",
        "\n",
        "# fit final RAW pipeline on TRAIN only\n",
        "best_params = study.best_params.copy()\n",
        "pre = ColumnTransformer([(\"num\", StandardScaler(), list(X_final.columns))], remainder=\"drop\", verbose_feature_names_out=False)\n",
        "est = make_xgb(best_params); est.set_params(scale_pos_weight=spw)\n",
        "pipe = Pipeline([(\"prep\", pre), (\"clf\", est)]).fit(X_tr, y_tr)\n",
        "\n",
        "# score holdout\n",
        "p_te = pipe.predict_proba(X_te)[:,1]\n",
        "\n",
        "# build signals from saved policy\n",
        "rule = DECISION_RULE\n",
        "thr_long  = float(rule[\"thr_long\"])\n",
        "thr_short = float(rule[\"thr_short\"])\n",
        "min_hold  = int(rule[\"min_hold\"])\n",
        "tc_bps    = int(rule.get(\"tc_bps\", 5))\n",
        "mode      = rule.get(\"mode\",\"long_short\")\n",
        "\n",
        "def enforce_min_hold(signals: np.ndarray, min_hold: int) -> np.ndarray:\n",
        "    if min_hold <= 1: return signals.astype(int)\n",
        "    out = np.zeros_like(signals, dtype=int); cur, hold = 0, 0\n",
        "    for i, s in enumerate(signals.astype(int)):\n",
        "        if s == cur: hold += 1\n",
        "        else:\n",
        "            if hold >= min_hold: cur = s; hold = 1\n",
        "            else: hold += 1\n",
        "        out[i] = cur\n",
        "    return out\n",
        "\n",
        "if mode == \"long_only\":\n",
        "    raw_sig = (p_te >= thr_long).astype(int)\n",
        "else:\n",
        "    raw_sig = np.zeros_like(p_te, dtype=int)\n",
        "    raw_sig[p_te >= thr_long]  = 1\n",
        "    raw_sig[p_te <= thr_short] = -1\n",
        "\n",
        "sig = enforce_min_hold(raw_sig, min_hold)\n",
        "\n",
        "# backtest\n",
        "def backtest_signals_with_hold(dates, signals, prices, tc_bps=5):\n",
        "    sig_df = pd.DataFrame({DATE_COL: dates, \"signal\": signals.astype(int)})\n",
        "    df = sig_df.merge(prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "    df['pos_shift'] = df['signal'].shift(1).fillna(0)\n",
        "    df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    tc = (tc_bps/1e4)\n",
        "    df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*tc\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    return df\n",
        "\n",
        "def performance_stats(equity_curve, freq=252):\n",
        "    rets = np.log(equity_curve).diff().dropna()\n",
        "    ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "    ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "    sharpe = float(ann_ret / ann_vol) if ann_vol>0 else np.nan\n",
        "    peak = equity_curve.cummax()\n",
        "    dd = (equity_curve/peak - 1.0)\n",
        "    mdd = float(dd.min())\n",
        "    return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "bt = backtest_signals_with_hold(dates_te, sig, prices, tc_bps=tc_bps)\n",
        "stats = performance_stats(bt['equity'])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(bt[DATE_COL], bt['equity'])\n",
        "plt.title(f\"OOT Holdout Equity (from {str(split_date)[:10]}; tc={tc_bps} bps)\")\n",
        "plt.xlabel(DATE_COL); plt.ylabel(\"Equity (start=1.0)\")\n",
        "plt.grid(True, alpha=0.3); plt.show()\n",
        "\n",
        "print(\"Holdout split date:\", str(split_date)[:10])\n",
        "print(\"Holdout stats:\", {k: round(v,4) for k,v in stats.items()})\n"
      ],
      "metadata": {
        "id": "xHEyAxUGJPOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.2. Transaction-cost sensitivity (0–25 bps)"
      ],
      "metadata": {
        "id": "rZFFZjTWJXVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 16.2 (fixed) — Transaction-cost sensitivity (0–25 bps)\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "assert 'oof_df' in globals() and 'prices' in globals(), \"Need OOF predictions and price data.\"\n",
        "rule = DECISION_RULE\n",
        "thr_long, thr_short = float(rule[\"thr_long\"]), float(rule[\"thr_short\"])\n",
        "min_hold = int(rule[\"min_hold\"])\n",
        "mode = rule.get(\"mode\",\"long_short\")\n",
        "\n",
        "def mk_signals(probs, thrL, thrS, mode):\n",
        "    if mode == \"long_only\":\n",
        "        return (probs >= thrL).astype(int)\n",
        "    s = np.zeros_like(probs, dtype=int)\n",
        "    s[probs >= thrL] = 1\n",
        "    s[probs <= thrS] = -1\n",
        "    return s\n",
        "\n",
        "# Reuse helpers if not in scope\n",
        "if 'enforce_min_hold' not in globals():\n",
        "    def enforce_min_hold(signals: np.ndarray, min_hold: int) -> np.ndarray:\n",
        "        if min_hold <= 1: return signals.astype(int)\n",
        "        out = np.zeros_like(signals, dtype=int); cur, hold = 0, 0\n",
        "        for i, s in enumerate(signals.astype(int)):\n",
        "            if s == cur: hold += 1\n",
        "            else:\n",
        "                if hold >= min_hold: cur = s; hold = 1\n",
        "                else: hold += 1\n",
        "            out[i] = cur\n",
        "        return out\n",
        "\n",
        "if 'backtest_signals_with_hold' not in globals():\n",
        "    def backtest_signals_with_hold(dates, signals, prices, tc_bps=5):\n",
        "        sig_df = pd.DataFrame({DATE_COL: dates, \"signal\": signals.astype(int)})\n",
        "        df = sig_df.merge(prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "        df['r1'] = df['logret'].shift(-1)\n",
        "        df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "        df['pos_shift'] = df['signal'].shift(1).fillna(0)\n",
        "        df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "        tc = (tc_bps/1e4)\n",
        "        df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*tc\n",
        "        df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "        return df\n",
        "\n",
        "if 'performance_stats' not in globals():\n",
        "    def performance_stats(equity_curve, freq=252):\n",
        "        rets = np.log(equity_curve).diff().dropna()\n",
        "        ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "        ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "        sharpe = float(ann_ret / ann_vol) if ann_vol>0 else np.nan\n",
        "        peak = equity_curve.cummax()\n",
        "        dd = (equity_curve/peak - 1.0)\n",
        "        mdd = float(dd.min())\n",
        "        return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "def run_bt(dates, signals, costs):\n",
        "    sig = enforce_min_hold(signals, min_hold)\n",
        "    bt = backtest_signals_with_hold(dates, sig, prices, tc_bps=costs)\n",
        "    return performance_stats(bt['equity'])\n",
        "\n",
        "costs = [0, 5, 10, 25]\n",
        "rows = []\n",
        "\n",
        "# --- OOF block ---\n",
        "dates_oof = oof_df[DATE_COL].values\n",
        "probs_oof = oof_df[\"p_hat\"].values\n",
        "sig_oof   = mk_signals(probs_oof, thr_long, thr_short, mode)\n",
        "\n",
        "for c in costs:\n",
        "    st = run_bt(dates_oof, sig_oof, c)\n",
        "    rows.append(dict(block=\"OOF\", tc_bps=c, **{k: round(v,4) for k,v in st.items()}))\n",
        "\n",
        "# --- OOT block (only if 16.1 ran) ---\n",
        "if 'dates_te' in globals():\n",
        "    if 'p_te' in globals():\n",
        "        sig_oot = mk_signals(p_te, thr_long, thr_short, mode)\n",
        "    elif 'sig' in globals() and len(sig) == len(globals().get('dates_te', [])):\n",
        "        # reuse precomputed signals from 16.1 if available and aligned\n",
        "        sig_oot = sig\n",
        "    else:\n",
        "        sig_oot = None\n",
        "\n",
        "    if sig_oot is not None and len(sig_oot) == len(dates_te):\n",
        "        for c in costs:\n",
        "            st = run_bt(dates_te, sig_oot, c)\n",
        "            rows.append(dict(block=\"OOT\", tc_bps=c, **{k: round(v,4) for k,v in st.items()}))\n",
        "    else:\n",
        "        print(\"Skipping OOT cost sweep: missing or misaligned (dates_te, p_te/sig).\")\n",
        "\n",
        "df_cost = pd.DataFrame(rows)\n",
        "display(df_cost)\n"
      ],
      "metadata": {
        "id": "4TvqguoKLKXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17.1. Baseline vs Tuned (robust OOF comparison at best threshold)**\n",
        "\n",
        "**Loads what it can find:**\n",
        "\n",
        "\n",
        "**baseline:**\n",
        "artifacts/oof_predictions_baseline.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**tuned_raw:**\n",
        "artifacts/raw_valthr/oof_predictions_raw.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**tuned_cal:**\n",
        "artifacts/tuned_mcc_valthr/oof_predictions_calibrated.csv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**tuned_misc (optional legacy):**\n",
        "artifacts/oof_predictions_tuned.csv\n",
        "\n",
        "\n",
        "**current_in_memory:**\n",
        "from y_oof, p_oof (whatever you ran last)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Computes each variant’s best MCC threshold and metrics."
      ],
      "metadata": {
        "id": "QnqONZtfMWZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 17.1 Baseline vs Tuned: OOF metrics at best threshold (robust loader) ---\n",
        "\n",
        "import os, json, numpy as np, pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, matthews_corrcoef\n",
        "from IPython.display import display\n",
        "\n",
        "def try_load_csv(path):\n",
        "    return pd.read_csv(path) if os.path.exists(path) else None\n",
        "\n",
        "def best_thr_mcc(y, p):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_m = 0.5, -1\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y, (p>=t).astype(int))\n",
        "        if m>best_m:\n",
        "            best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "def oof_scores(y, p, thr):\n",
        "    return dict(\n",
        "        roc_auc = float(roc_auc_score(y,p)),\n",
        "        pr_auc  = float(average_precision_score(y,p)),\n",
        "        brier   = float(brier_score_loss(y,p)),\n",
        "        mcc     = float(matthews_corrcoef(y,(p>=thr).astype(int))),\n",
        "        thr     = float(thr),\n",
        "        n       = int(len(y))\n",
        "    )\n",
        "\n",
        "# Candidate sources\n",
        "cands = []\n",
        "\n",
        "# 1) Baseline (if saved)\n",
        "df_base = try_load_csv(\"artifacts/oof_predictions_baseline.csv\")\n",
        "if df_base is not None and {'y_true','p_hat'}.issubset(df_base.columns):\n",
        "    yb, pb = df_base['y_true'].values, df_base['p_hat'].values\n",
        "    cands.append((\"baseline\", yb, pb, df_base))\n",
        "\n",
        "# 2) Tuned (raw)\n",
        "df_raw = try_load_csv(\"artifacts/raw_valthr/oof_predictions_raw.csv\")\n",
        "if df_raw is not None and {'y_true','p_hat'}.issubset(df_raw.columns):\n",
        "    yr, pr = df_raw['y_true'].values, df_raw['p_hat'].values\n",
        "    cands.append((\"tuned_raw\", yr, pr, df_raw))\n",
        "\n",
        "# 3) Tuned (calibrated)\n",
        "df_cal = try_load_csv(\"artifacts/tuned_mcc_valthr/oof_predictions_calibrated.csv\")\n",
        "if df_cal is not None and {'y_true','p_hat'}.issubset(df_cal.columns):\n",
        "    yc, pc = df_cal['y_true'].values, df_cal['p_hat'].values\n",
        "    cands.append((\"tuned_cal\", yc, pc, df_cal))\n",
        "\n",
        "# 4) Legacy tuned (if any)\n",
        "df_tuned_misc = try_load_csv(\"artifacts/oof_predictions_tuned.csv\")\n",
        "if df_tuned_misc is not None and {'y_true','p_hat'}.issubset(df_tuned_misc.columns):\n",
        "    yt, pt = df_tuned_misc['y_true'].values, df_tuned_misc['p_hat'].values\n",
        "    cands.append((\"tuned_misc\", yt, pt, df_tuned_misc))\n",
        "\n",
        "# 5) Current in-memory (whatever you last set y_oof/p_oof to)\n",
        "if 'y_oof' in globals() and 'p_oof' in globals():\n",
        "    cands.append((\"current_in_memory\", np.asarray(y_oof), np.asarray(p_oof), None))\n",
        "\n",
        "rows = []\n",
        "for name, yv, pv, df in cands:\n",
        "    if len(yv) != len(pv) or len(yv) == 0:\n",
        "        continue\n",
        "    t_best, m_best = best_thr_mcc(yv, pv)\n",
        "    s_best = oof_scores(yv, pv, t_best)\n",
        "    s_05   = oof_scores(yv, pv, 0.5)\n",
        "    rows.append(dict(\n",
        "        variant=name,\n",
        "        **{f\"best_{k}\": round(v,4) if isinstance(v,(int,float,np.floating)) else v for k,v in s_best.items()},\n",
        "        **{f\"thr0p5_{k}\": round(v,4) if isinstance(v,(int,float,np.floating)) else v for k,v in s_05.items()}\n",
        "    ))\n",
        "\n",
        "df_cmp = pd.DataFrame(rows)\n",
        "if not df_cmp.empty:\n",
        "    display(df_cmp.sort_values(\"best_mcc\", ascending=False))\n",
        "else:\n",
        "    print(\"No OOF sources found. Make sure artifacts exist or y_oof/p_oof are in memory.\")\n"
      ],
      "metadata": {
        "id": "yqL1iFItM0Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17.2. PnL sanity across variants at their best thresholds**\n",
        "\n",
        "Uses backtest_from_oof if present (from Section 12.1), otherwise defines a lightweight fallback.\n",
        "\n",
        "Compares long-only and long/short with a given cost."
      ],
      "metadata": {
        "id": "oGMYc0IwM8jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 17.2 (final fix) — PnL sanity across variants (best thresholds), dtype-safe & load-safe ---\n",
        "\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "TC_BPS = globals().get(\"TC_BPS\", 5)\n",
        "\n",
        "def _normalize_dt(s):\n",
        "    c = pd.to_datetime(s, errors=\"coerce\")\n",
        "    try: return c.dt.tz_localize(None)\n",
        "    except Exception: return c\n",
        "\n",
        "def performance_stats(equity_curve, freq=252):\n",
        "    rets = np.log(equity_curve).diff().dropna()\n",
        "    ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "    ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "    sharpe = float(ann_ret / ann_vol) if ann_vol>0 else np.nan\n",
        "    peak = equity_curve.cummax()\n",
        "    dd = (equity_curve/peak - 1.0)\n",
        "    mdd = float(dd.min())\n",
        "    return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "def backtest_from_oof(oof_df, prices, t_best, tc_bps=5, mode=\"long_only\"):\n",
        "    o = oof_df.copy()\n",
        "    px = prices[[DATE_COL, 'logret']].copy()\n",
        "    o[DATE_COL]  = _normalize_dt(o[DATE_COL])\n",
        "    px[DATE_COL] = _normalize_dt(px[DATE_COL])\n",
        "    o = o.dropna(subset=[DATE_COL]).drop_duplicates(subset=[DATE_COL])\n",
        "    px= px.dropna(subset=[DATE_COL]).drop_duplicates(subset=[DATE_COL])\n",
        "\n",
        "    df = o.merge(px, on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "\n",
        "    if mode == \"long_only\":\n",
        "        df['pos'] = (df['p_hat'] >= t_best).astype(int)\n",
        "    elif mode == \"long_short\":\n",
        "        df['pos'] = 0\n",
        "        df.loc[df['p_hat'] >= t_best, 'pos'] = 1\n",
        "        df.loc[df['p_hat'] <= (1 - t_best), 'pos'] = -1\n",
        "    else:\n",
        "        raise ValueError(\"Unknown mode\")\n",
        "\n",
        "    df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "    df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    tc = (tc_bps / 1e4)\n",
        "    df['ret_strategy'] = df['pos_shift'] * df['r1'] - df['turnover'] * tc\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    return df, performance_stats(df['equity'])\n",
        "\n",
        "def best_thr_mcc(y, p):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_m = 0.5, -1\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y, (p>=t).astype(int))\n",
        "        if m > best_m: best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "def _try_load(path):\n",
        "    return pd.read_csv(path) if os.path.exists(path) else None\n",
        "\n",
        "def pick_df(name, path):\n",
        "    obj = globals().get(name, None)\n",
        "    if isinstance(obj, pd.DataFrame) and not obj.empty:\n",
        "        return obj\n",
        "    return _try_load(path)\n",
        "\n",
        "# Load candidates safely (no ambiguous DataFrame truth checks)\n",
        "df_base = pick_df(\"df_base\", \"artifacts/oof_predictions_baseline.csv\")\n",
        "df_raw  = pick_df(\"df_raw\",  \"artifacts/raw_valthr/oof_predictions_raw.csv\")\n",
        "df_cal  = pick_df(\"df_cal\",  \"artifacts/tuned_mcc_valthr/oof_predictions_calibrated.csv\")\n",
        "df_misc = pick_df(\"df_tuned_misc\", \"artifacts/oof_predictions_tuned.csv\")\n",
        "\n",
        "def pnl_for_variant(name, df_src, y, p):\n",
        "    # choose dates: prefer provided df_src dates; otherwise borrow from current oof_df\n",
        "    if df_src is not None and DATE_COL in df_src.columns:\n",
        "        dates = df_src[DATE_COL].values\n",
        "    else:\n",
        "        assert 'oof_df' in globals() and DATE_COL in oof_df.columns, f\"{name}: missing dates; need oof_df.\"\n",
        "        dates = oof_df[DATE_COL].values\n",
        "\n",
        "    # length guard: trim to common tail if mismatch\n",
        "    n = min(len(dates), len(y), len(p))\n",
        "    dates, y, p = dates[-n:], y[-n:], p[-n:]\n",
        "\n",
        "    t, _ = best_thr_mcc(y, p)\n",
        "    oof_local = pd.DataFrame({DATE_COL: dates, \"y_true\": y, \"p_hat\": p})\n",
        "    btL, stL = backtest_from_oof(oof_local, prices, t_best=t, tc_bps=TC_BPS, mode=\"long_only\")\n",
        "    btS, stS = backtest_from_oof(oof_local, prices, t_best=t, tc_bps=TC_BPS, mode=\"long_short\")\n",
        "    return dict(\n",
        "        variant=name, thr_best=round(t,3),\n",
        "        long_CAGR=round(stL['CAGR'],4), long_Sharpe=round(stL['Sharpe'],4), long_MaxDD=round(stL['MaxDD'],4),\n",
        "        ls_CAGR=round(stS['CAGR'],4),   ls_Sharpe=round(stS['Sharpe'],4),   ls_MaxDD=round(stS['MaxDD'],4),\n",
        "    )\n",
        "\n",
        "rows = []\n",
        "for name, df_src in [(\"baseline\", df_base), (\"tuned_raw\", df_raw), (\"tuned_cal\", df_cal), (\"tuned_misc\", df_misc)]:\n",
        "    if df_src is not None and {'y_true','p_hat'}.issubset(df_src.columns):\n",
        "        yv, pv = df_src['y_true'].values, df_src['p_hat'].values\n",
        "        rows.append(pnl_for_variant(name, df_src, yv, pv))\n",
        "\n",
        "if 'y_oof' in globals() and 'p_oof' in globals():\n",
        "    rows.append(pnl_for_variant(\"current_in_memory\", globals().get(\"oof_df\", None),\n",
        "                                np.asarray(y_oof), np.asarray(p_oof)))\n",
        "\n",
        "df_pnl_cmp = pd.DataFrame(rows)\n",
        "display(df_pnl_cmp.sort_values(\"ls_Sharpe\", ascending=False) if not df_pnl_cmp.empty else pd.DataFrame([{\"note\":\"No variants available\"}]))\n"
      ],
      "metadata": {
        "id": "zxJZMan9Ow8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17.F1. Load variants & compute OOF metrics at each variant’s best MCC threshold**"
      ],
      "metadata": {
        "id": "ue4XbKFBfm_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 17.F1 Baseline vs Tuned: OOF metrics @ best threshold (robust loader) ---\n",
        "\n",
        "import os, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, matthews_corrcoef\n",
        "\n",
        "ARTDIR = Path(\"artifacts/comparison\"); ARTDIR.mkdir(parents=True, exist_ok=True)\n",
        "DATE_COL = globals().get(\"DATE_COL\", \"Date\")\n",
        "\n",
        "def try_load(path):\n",
        "    return pd.read_csv(path) if Path(path).exists() else None\n",
        "\n",
        "def best_thr_mcc(y, p):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_m = 0.5, -1.0\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y, (p >= t).astype(int))\n",
        "        if m > best_m:\n",
        "            best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "def oof_scores(y, p, thr):\n",
        "    return dict(\n",
        "        roc_auc = float(roc_auc_score(y, p)),\n",
        "        pr_auc  = float(average_precision_score(y, p)),\n",
        "        brier   = float(brier_score_loss(y, p)),\n",
        "        mcc     = float(matthews_corrcoef(y, (p >= thr).astype(int))),\n",
        "        thr     = float(thr),\n",
        "        n       = int(len(y)),\n",
        "    )\n",
        "\n",
        "# Candidate OOF sources\n",
        "sources = []\n",
        "\n",
        "# 1) Baseline (if saved)\n",
        "df_base = try_load(\"artifacts/oof_predictions_baseline.csv\")\n",
        "if df_base is not None and {'y_true','p_hat'}.issubset(df_base.columns):\n",
        "    sources.append((\"baseline\", df_base))\n",
        "\n",
        "# 2) Tuned RAW (your best)\n",
        "df_raw = try_load(\"artifacts/raw_valthr/oof_predictions_raw.csv\")\n",
        "if df_raw is not None and {'y_true','p_hat'}.issubset(df_raw.columns):\n",
        "    sources.append((\"tuned_raw\", df_raw))\n",
        "\n",
        "# 3) Tuned calibrated (for reference)\n",
        "df_cal = try_load(\"artifacts/tuned_mcc_valthr/oof_predictions_calibrated.csv\")\n",
        "if df_cal is not None and {'y_true','p_hat'}.issubset(df_cal.columns):\n",
        "    sources.append((\"tuned_cal\", df_cal))\n",
        "\n",
        "# 4) Legacy tuned (optional)\n",
        "df_misc = try_load(\"artifacts/oof_predictions_tuned.csv\")\n",
        "if df_misc is not None and {'y_true','p_hat'}.issubset(df_misc.columns):\n",
        "    sources.append((\"tuned_misc\", df_misc))\n",
        "\n",
        "# 5) Current in-memory (whatever you last set y_oof/p_oof to)\n",
        "if 'y_oof' in globals() and 'p_oof' in globals():\n",
        "    if 'oof_df' in globals() and DATE_COL in oof_df.columns:\n",
        "        df_cur = pd.DataFrame({DATE_COL: oof_df[DATE_COL].values, \"y_true\": np.asarray(y_oof), \"p_hat\": np.asarray(p_oof)})\n",
        "    else:\n",
        "        # fallback: no dates; we'll borrow from prices later for PnL\n",
        "        df_cur = pd.DataFrame({\"y_true\": np.asarray(y_oof), \"p_hat\": np.asarray(p_oof)})\n",
        "    sources.append((\"current_in_memory\", df_cur))\n",
        "\n",
        "# --- Build metric table ---\n",
        "metric_rows = []\n",
        "for name, df_src in sources:\n",
        "    if not {'y_true','p_hat'}.issubset(df_src.columns):\n",
        "        continue\n",
        "    y = df_src['y_true'].values\n",
        "    p = df_src['p_hat'].values\n",
        "    n = min(len(y), len(p))\n",
        "    if n == 0:\n",
        "        continue\n",
        "    y, p = y[-n:], p[-n:]\n",
        "    t_best, _ = best_thr_mcc(y, p)\n",
        "    s_best = oof_scores(y, p, t_best)\n",
        "    s_05   = oof_scores(y, p, 0.5)\n",
        "    metric_rows.append({\n",
        "        \"variant\": name,\n",
        "        \"best_thr\": round(s_best['thr'], 3),\n",
        "        \"best_roc_auc\": round(s_best['roc_auc'], 4),\n",
        "        \"best_pr_auc\": round(s_best['pr_auc'], 4),\n",
        "        \"best_brier\": round(s_best['brier'], 5),\n",
        "        \"best_mcc\": round(s_best['mcc'], 4),\n",
        "        \"thr0p5_roc_auc\": round(s_05['roc_auc'], 4),\n",
        "        \"thr0p5_pr_auc\": round(s_05['pr_auc'], 4),\n",
        "        \"thr0p5_brier\": round(s_05['brier'], 5),\n",
        "        \"thr0p5_mcc\": round(s_05['mcc'], 4),\n",
        "        \"n\": s_best['n']\n",
        "    })\n",
        "\n",
        "df_metrics = pd.DataFrame(metric_rows).sort_values(\"best_mcc\", ascending=False)\n",
        "display(df_metrics)\n",
        "\n",
        "# Save\n",
        "df_metrics.to_csv(ARTDIR/\"oof_metrics_best_vs_05.csv\", index=False)\n",
        "with open(ARTDIR/\"oof_metrics_best_vs_05.json\",\"w\") as f:\n",
        "    json.dump(df_metrics.to_dict(orient=\"records\"), f, indent=2)\n",
        "\n",
        "print(\"Saved OOF metrics to:\", ARTDIR/\"oof_metrics_best_vs_05.csv\")\n"
      ],
      "metadata": {
        "id": "Y-WiltRffor1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17.F2. PnL at each variant’s best threshold (long-only & long/short), dtype-safe dates**"
      ],
      "metadata": {
        "id": "tJEa_mxLf0D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 17.F2 PnL at best threshold for each variant (robust date handling) ---\n",
        "\n",
        "import os, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "assert 'prices' in globals(), \"Missing `prices` in memory. Run your data loading cell first.\"\n",
        "DATE_COL = globals().get(\"DATE_COL\", \"Date\")\n",
        "TC_BPS   = int(globals().get(\"TC_BPS\", 5))\n",
        "ARTDIR   = Path(\"artifacts/comparison\"); ARTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _norm_dt(s):\n",
        "    c = pd.to_datetime(s, errors=\"coerce\")\n",
        "    try: return c.dt.tz_localize(None)\n",
        "    except Exception: return c\n",
        "\n",
        "# Ensure log returns exist\n",
        "if 'logret' not in prices.columns:\n",
        "    if 'Close' in prices.columns:\n",
        "        prices = prices.copy()\n",
        "        prices['logret'] = np.log(prices['Close']).diff()\n",
        "    else:\n",
        "        raise ValueError(\"`prices` must include 'logret' or 'Close'.\")\n",
        "\n",
        "# Reload the same sources as in 17.F1\n",
        "def try_load(path):\n",
        "    return pd.read_csv(path) if Path(path).exists() else None\n",
        "\n",
        "srcs = []\n",
        "for name, path in [\n",
        "    (\"baseline\", \"artifacts/oof_predictions_baseline.csv\"),\n",
        "    (\"tuned_raw\", \"artifacts/raw_valthr/oof_predictions_raw.csv\"),\n",
        "    (\"tuned_cal\", \"artifacts/tuned_mcc_valthr/oof_predictions_calibrated.csv\"),\n",
        "    (\"tuned_misc\",\"artifacts/oof_predictions_tuned.csv\"),\n",
        "]:\n",
        "    df = try_load(path)\n",
        "    if df is not None and {'y_true','p_hat'}.issubset(df.columns):\n",
        "        srcs.append((name, df))\n",
        "\n",
        "# Add current in-memory if available\n",
        "if 'y_oof' in globals() and 'p_oof' in globals():\n",
        "    if 'oof_df' in globals() and DATE_COL in oof_df.columns:\n",
        "        df_cur = pd.DataFrame({DATE_COL: oof_df[DATE_COL].values, \"y_true\": np.asarray(y_oof), \"p_hat\": np.asarray(p_oof)})\n",
        "    else:\n",
        "        # we'll borrow dates from prices (tail match)\n",
        "        k = len(y_oof)\n",
        "        d0 = prices[DATE_COL].iloc[-k:].values if len(prices)>=k else np.arange(k)\n",
        "        df_cur = pd.DataFrame({DATE_COL: d0, \"y_true\": np.asarray(y_oof), \"p_hat\": np.asarray(p_oof)})\n",
        "    srcs.append((\"current_in_memory\", df_cur))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "def best_thr_mcc(y, p):\n",
        "    grid = np.linspace(0.05, 0.95, 37)\n",
        "    best_t, best_m = 0.5, -1.0\n",
        "    for t in grid:\n",
        "        m = matthews_corrcoef(y, (p >= t).astype(int))\n",
        "        if m > best_m:\n",
        "            best_t, best_m = float(t), float(m)\n",
        "    return best_t, best_m\n",
        "\n",
        "def performance_stats(equity_curve, freq=252):\n",
        "    rets = np.log(equity_curve).diff().dropna()\n",
        "    ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "    ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "    sharpe  = float(ann_ret / ann_vol) if ann_vol > 0 else np.nan\n",
        "    peak    = equity_curve.cummax()\n",
        "    dd      = (equity_curve/peak - 1.0)\n",
        "    mdd     = float(dd.min())\n",
        "    return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "def backtest_from_oof(oof_df, prices, t_best, tc_bps=5, mode=\"long_only\"):\n",
        "    o = oof_df.copy()\n",
        "    px = prices[[DATE_COL, 'logret']].copy()\n",
        "    o[DATE_COL]  = _norm_dt(o[DATE_COL])\n",
        "    px[DATE_COL] = _norm_dt(px[DATE_COL])\n",
        "    o  = o.dropna(subset=[DATE_COL]).drop_duplicates(subset=[DATE_COL])\n",
        "    px = px.dropna(subset=[DATE_COL]).drop_duplicates(subset=[DATE_COL])\n",
        "\n",
        "    df = o.merge(px, on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "\n",
        "    if mode == \"long_only\":\n",
        "        df['pos'] = (df['p_hat'] >= t_best).astype(int)\n",
        "    elif mode == \"long_short\":\n",
        "        df['pos'] = 0\n",
        "        df.loc[df['p_hat'] >= t_best, 'pos'] = 1\n",
        "        df.loc[df['p_hat'] <= (1 - t_best), 'pos'] = -1\n",
        "    else:\n",
        "        raise ValueError(\"Unknown mode\")\n",
        "\n",
        "    df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "    df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    tc = (tc_bps / 1e4)\n",
        "    df['ret_strategy'] = df['pos_shift'] * df['r1'] - df['turnover'] * tc\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    return df, performance_stats(df['equity'])\n",
        "\n",
        "# Compute PnL blocks\n",
        "pnl_rows = []\n",
        "for name, df_src in srcs:\n",
        "    if not {'y_true','p_hat', DATE_COL}.issubset(df_src.columns):\n",
        "        # skip if dates missing (shouldn't happen after 17.F1 paths)\n",
        "        continue\n",
        "    y = df_src['y_true'].values\n",
        "    p = df_src['p_hat'].values\n",
        "    d = df_src[DATE_COL].values\n",
        "    n = min(len(y), len(p), len(d))\n",
        "    if n == 0:\n",
        "        continue\n",
        "    y, p, d = y[-n:], p[-n:], d[-n:]\n",
        "\n",
        "    t_best, _ = best_thr_mcc(y, p)\n",
        "    oof_local = pd.DataFrame({DATE_COL: d, \"y_true\": y, \"p_hat\": p})\n",
        "\n",
        "    btL, stL = backtest_from_oof(oof_local, prices, t_best=t_best, tc_bps=TC_BPS, mode=\"long_only\")\n",
        "    btS, stS = backtest_from_oof(oof_local, prices, t_best=t_best, tc_bps=TC_BPS, mode=\"long_short\")\n",
        "\n",
        "    pnl_rows.append(dict(\n",
        "        variant=name, thr_best=round(t_best,3), tc_bps=TC_BPS,\n",
        "        long_CAGR=round(stL['CAGR'],4), long_Sharpe=round(stL['Sharpe'],4), long_MaxDD=round(stL['MaxDD'],4),\n",
        "        ls_CAGR=round(stS['CAGR'],4),   ls_Sharpe=round(stS['Sharpe'],4),   ls_MaxDD=round(stS['MaxDD'],4),\n",
        "    ))\n",
        "\n",
        "df_pnl = pd.DataFrame(pnl_rows).sort_values(\"ls_Sharpe\", ascending=False)\n",
        "display(df_pnl)\n",
        "\n",
        "# Save\n",
        "df_pnl.to_csv(ARTDIR/\"pnl_at_best_threshold.csv\", index=False)\n",
        "with open(ARTDIR/\"pnl_at_best_threshold.json\",\"w\") as f:\n",
        "    json.dump(df_pnl.to_dict(orient=\"records\"), f, indent=2)\n",
        "\n",
        "print(\"Saved PnL table to:\", ARTDIR/\"pnl_at_best_threshold.csv\")\n"
      ],
      "metadata": {
        "id": "rMO6NduQf46r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18.1. OOF stability by time (metrics & PnL by year and quarter)**"
      ],
      "metadata": {
        "id": "rIZ8yhgSk-WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 18.1 OOF stability by time: per-year & per-quarter metrics + PnL ---\n",
        "\n",
        "import numpy as np, pandas as pd, os, json, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, matthews_corrcoef\n",
        "from pathlib import Path\n",
        "\n",
        "# Guards & fallbacks\n",
        "assert 'oof_df' in globals() and {'y_true','p_hat'}.issubset(oof_df.columns), \"Need OOF oof_df with y_true & p_hat.\"\n",
        "assert 'prices' in globals() and 'logret' in prices.columns, \"Need prices with logret (run Section 6.1).\"\n",
        "DATE_COL = globals().get(\"DATE_COL\", \"Date\")\n",
        "TC_BPS   = int(globals().get(\"TC_BPS\", 5))\n",
        "\n",
        "if 'performance_stats' not in globals():\n",
        "    def performance_stats(equity_curve, freq=252):\n",
        "        rets = np.log(equity_curve).diff().dropna()\n",
        "        ann_ret = float(np.exp(rets.mean()*freq) - 1.0)\n",
        "        ann_vol = float(rets.std(ddof=1) * np.sqrt(freq))\n",
        "        sharpe = float(ann_ret / ann_vol) if ann_vol>0 else np.nan\n",
        "        peak = equity_curve.cummax()\n",
        "        dd = (equity_curve/peak - 1.0)\n",
        "        mdd = float(dd.min())\n",
        "        return {\"CAGR\": ann_ret, \"Sharpe\": sharpe, \"MaxDD\": mdd}\n",
        "\n",
        "if 'backtest_from_oof' not in globals():\n",
        "    def backtest_from_oof(oof_df, prices, t_best, tc_bps=5, mode=\"long_only\"):\n",
        "        df = oof_df.merge(prices[[DATE_COL, 'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "        df['r1'] = df['logret'].shift(-1)\n",
        "        df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "        if mode == \"long_only\":\n",
        "            df['pos'] = (df['p_hat'] >= t_best).astype(int)\n",
        "        elif mode == \"long_short\":\n",
        "            df['pos'] = 0\n",
        "            df.loc[df['p_hat'] >= t_best, 'pos'] = 1\n",
        "            df.loc[df['p_hat'] <= (1 - t_best), 'pos'] = -1\n",
        "        else:\n",
        "            raise ValueError(\"Unknown mode\")\n",
        "        df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "        df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "        tc = (tc_bps/1e4)\n",
        "        df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*tc\n",
        "        df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "        return df, performance_stats(df['equity'])\n",
        "\n",
        "def metrics_at_thr(y, p, thr):\n",
        "    return dict(\n",
        "        roc_auc = float(roc_auc_score(y,p)),\n",
        "        pr_auc  = float(average_precision_score(y,p)),\n",
        "        brier   = float(brier_score_loss(y,p)),\n",
        "        mcc     = float(matthews_corrcoef(y,(p>=thr).astype(int)))\n",
        "    )\n",
        "\n",
        "# Prep\n",
        "oo = oof_df.copy()\n",
        "oo[DATE_COL] = pd.to_datetime(oo[DATE_COL])\n",
        "oo['year']   = oo[DATE_COL].dt.year\n",
        "oo['q']      = oo[DATE_COL].dt.to_period('Q').astype(str)\n",
        "\n",
        "thr = float(globals().get(\"t_best\", 0.5))  # use your global best\n",
        "\n",
        "rows_y, rows_q = [], []\n",
        "for y, g in oo.groupby('year'):\n",
        "    m = metrics_at_thr(g['y_true'].values, g['p_hat'].values, thr)\n",
        "    btL, stL = backtest_from_oof(g[[DATE_COL, 'y_true','p_hat']], prices, thr, TC_BPS, mode=\"long_only\")\n",
        "    btS, stS = backtest_from_oof(g[[DATE_COL, 'y_true','p_hat']], prices, thr, TC_BPS, mode=\"long_short\")\n",
        "    rows_y.append(dict(period=str(y), n=len(g), **{f\"metric_{k}\":round(v,4) for k,v in m.items()},\n",
        "                       long_CAGR=round(stL['CAGR'],4), long_Sharpe=round(stL['Sharpe'],4), long_MaxDD=round(stL['MaxDD'],4),\n",
        "                       ls_CAGR=round(stS['CAGR'],4),   ls_Sharpe=round(stS['Sharpe'],4),   ls_MaxDD=round(stS['MaxDD'],4)))\n",
        "\n",
        "for q, g in oo.groupby('q'):\n",
        "    m = metrics_at_thr(g['y_true'].values, g['p_hat'].values, thr)\n",
        "    btL, stL = backtest_from_oof(g[[DATE_COL, 'y_true','p_hat']], prices, thr, TC_BPS, mode=\"long_only\")\n",
        "    btS, stS = backtest_from_oof(g[[DATE_COL, 'y_true','p_hat']], prices, thr, TC_BPS, mode=\"long_short\")\n",
        "    rows_q.append(dict(period=str(q), n=len(g), **{f\"metric_{k}\":round(v,4) for k,v in m.items()},\n",
        "                       long_CAGR=round(stL['CAGR'],4), long_Sharpe=round(stL['Sharpe'],4), long_MaxDD=round(stL['MaxDD'],4),\n",
        "                       ls_CAGR=round(stS['CAGR'],4),   ls_Sharpe=round(stS['Sharpe'],4),   ls_MaxDD=round(stS['MaxDD'],4)))\n",
        "\n",
        "df_year   = pd.DataFrame(rows_y).sort_values('period')\n",
        "df_quarter= pd.DataFrame(rows_q).sort_values('period')\n",
        "\n",
        "Path(\"artifacts/checks\").mkdir(parents=True, exist_ok=True)\n",
        "df_year.to_csv(\"artifacts/checks/oof_stability_by_year.csv\", index=False)\n",
        "df_quarter.to_csv(\"artifacts/checks/oof_stability_by_quarter.csv\", index=False)\n",
        "\n",
        "print(\"OOF stability by year:\")\n",
        "display(df_year)\n",
        "print(\"\\nOOF stability by quarter:\")\n",
        "display(df_quarter)\n"
      ],
      "metadata": {
        "id": "FFnE6VNflFEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18.2. Cost & turnover sensitivity (uses global threshold and your policy)**"
      ],
      "metadata": {
        "id": "thA3W3uOlJhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 18.2 Cost & turnover sensitivity: turnover, Sharpe across bps ---\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "assert 'oof_df' in globals() and 'prices' in globals()\n",
        "DATE_COL = globals().get(\"DATE_COL\",\"Date\")\n",
        "thr      = float(globals().get(\"t_best\", 0.5))\n",
        "rule     = globals().get(\"DECISION_RULE\", None)\n",
        "\n",
        "if 'enforce_min_hold' not in globals():\n",
        "    def enforce_min_hold(signals: np.ndarray, min_hold: int) -> np.ndarray:\n",
        "        if min_hold <= 1: return signals.astype(int)\n",
        "        out = np.zeros_like(signals, dtype=int); cur, hold = 0, 0\n",
        "        for i, s in enumerate(signals.astype(int)):\n",
        "            if s == cur: hold += 1\n",
        "            else:\n",
        "                if hold >= min_hold: cur = s; hold = 1\n",
        "                else: hold += 1\n",
        "            out[i] = cur\n",
        "        return out\n",
        "\n",
        "def backtest_collect(oof_df, prices, thr, tc_bps=5, mode=\"long_only\"):\n",
        "    df = oof_df.merge(prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1)\n",
        "    df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "    if mode==\"long_only\":\n",
        "        df['pos'] = (df['p_hat']>=thr).astype(int)\n",
        "    else:\n",
        "        df['pos'] = 0\n",
        "        df.loc[df['p_hat']>=thr, 'pos'] = 1\n",
        "        df.loc[df['p_hat']<=(1-thr), 'pos'] = -1\n",
        "    df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "    df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    cost = (tc_bps/1e4)\n",
        "    df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*cost\n",
        "    df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "    # stats\n",
        "    rets = np.log(df['equity']).diff().dropna()\n",
        "    ann_ret = float(np.exp(rets.mean()*252)-1.0)\n",
        "    ann_vol = float(rets.std(ddof=1)*np.sqrt(252))\n",
        "    sharpe  = float(ann_ret/ann_vol) if ann_vol>0 else np.nan\n",
        "    peak = df['equity'].cummax(); mdd = float((df['equity']/peak - 1).min())\n",
        "    return dict(Sharpe=sharpe, CAGR=ann_ret, MaxDD=mdd,\n",
        "                mean_daily_turnover=float(df['turnover'].mean()),\n",
        "                annual_turns=float(df['turnover'].sum())/(len(df)/252.0))\n",
        "\n",
        "costs = [0, 5, 10, 25]\n",
        "rows = []\n",
        "\n",
        "# A) Global threshold, long-only & long/short\n",
        "for c in costs:\n",
        "    stL = backtest_collect(oof_df[[DATE_COL,'y_true','p_hat']], prices, thr, tc_bps=c, mode=\"long_only\")\n",
        "    stS = backtest_collect(oof_df[[DATE_COL,'y_true','p_hat']], prices, thr, tc_bps=c, mode=\"long_short\")\n",
        "    rows.append(dict(policy=\"global_thr_long_only\", tc_bps=c, **{k:round(v,4) for k,v in stL.items()}))\n",
        "    rows.append(dict(policy=\"global_thr_long_short\", tc_bps=c, **{k:round(v,4) for k,v in stS.items()}))\n",
        "\n",
        "# B) Your band+min_hold policy (if set)\n",
        "if rule is not None:\n",
        "    p = oof_df['p_hat'].values\n",
        "    d = oof_df[DATE_COL].values\n",
        "    thrL = float(rule['thr_long']); thrS = float(rule['thr_short']); hold=int(rule['min_hold'])\n",
        "    mode = rule.get(\"mode\",\"long_short\")\n",
        "    if mode==\"long_only\":\n",
        "        sig = enforce_min_hold((p>=thrL).astype(int), hold)\n",
        "    else:\n",
        "        sig = np.zeros_like(p, dtype=int); sig[p>=thrL]=1; sig[p<=thrS]=-1; sig = enforce_min_hold(sig, hold)\n",
        "\n",
        "    def backtest_policy(dates, sig, prices, tc_bps=5):\n",
        "        df = pd.DataFrame({DATE_COL:dates, \"signal\":sig.astype(int)}).merge(\n",
        "            prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "        df['r1'] = df['logret'].shift(-1); df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "        df['pos_shift'] = df['signal'].shift(1).fillna(0)\n",
        "        df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "        cost = (tc_bps/1e4)\n",
        "        df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*cost\n",
        "        df['equity'] = np.exp(df['ret_strategy'].cumsum())\n",
        "        rets = np.log(df['equity']).diff().dropna()\n",
        "        ann_ret = float(np.exp(rets.mean()*252)-1.0)\n",
        "        ann_vol = float(rets.std(ddof=1)*np.sqrt(252))\n",
        "        sharpe  = float(ann_ret/ann_vol) if ann_vol>0 else np.nan\n",
        "        peak = df['equity'].cummax(); mdd = float((df['equity']/peak - 1).min())\n",
        "        return dict(Sharpe=sharpe, CAGR=ann_ret, MaxDD=mdd,\n",
        "                    mean_daily_turnover=float(df['turnover'].mean()),\n",
        "                    annual_turns=float(df['turnover'].sum())/(len(df)/252.0))\n",
        "\n",
        "    for c in costs:\n",
        "        stP = backtest_policy(d, sig, prices, tc_bps=c)\n",
        "        rows.append(dict(policy=f\"band_hold({mode})\", tc_bps=c, **{k:round(v,4) for k,v in stP.items()}))\n",
        "\n",
        "df_cost = pd.DataFrame(rows).sort_values([\"policy\",\"tc_bps\"])\n",
        "Path(\"artifacts/checks\").mkdir(parents=True, exist_ok=True)\n",
        "df_cost.to_csv(\"artifacts/checks/cost_turnover_sensitivity.csv\", index=False)\n",
        "print(\"Cost & turnover sensitivity:\")\n",
        "display(df_cost)\n"
      ],
      "metadata": {
        "id": "bF1Lugx-lOns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18.3. Rolling stability (6-month) for AUC/MCC and rolling Sharpe at global threshold**"
      ],
      "metadata": {
        "id": "g-ZSwpkTla-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 18.3 Rolling stability (6M windows): AUC, MCC, and rolling Sharpe ---\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
        "\n",
        "assert 'oof_df' in globals() and 'prices' in globals()\n",
        "DATE_COL = globals().get(\"DATE_COL\",\"Date\")\n",
        "thr      = float(globals().get(\"t_best\", 0.5))\n",
        "WIN_DAYS = 126   # ~6 months on trading days\n",
        "\n",
        "oo = oof_df.copy()\n",
        "oo[DATE_COL] = pd.to_datetime(oo[DATE_COL])\n",
        "oo = oo.sort_values(DATE_COL).reset_index(drop=True)\n",
        "\n",
        "# Rolling metrics\n",
        "roll_rows = []\n",
        "y = oo['y_true'].values; p = oo['p_hat'].values; d = oo[DATE_COL].values\n",
        "for i in range(WIN_DAYS, len(oo)+1):\n",
        "    y_w = y[i-WIN_DAYS:i]; p_w = p[i-WIN_DAYS:i]; d_w = d[i-1]\n",
        "    try:\n",
        "        auc = float(roc_auc_score(y_w, p_w))\n",
        "        mcc = float(matthews_corrcoef(y_w, (p_w>=thr).astype(int)))\n",
        "    except Exception:\n",
        "        auc, mcc = np.nan, np.nan\n",
        "    roll_rows.append({\"date\": d_w, \"auc_6m\": auc, \"mcc_6m\": mcc})\n",
        "\n",
        "df_roll = pd.DataFrame(roll_rows)\n",
        "\n",
        "# Rolling Sharpe via simple global-threshold backtest returns\n",
        "def backtest_ret_series(oof_df, prices, thr, tc_bps=5):\n",
        "    df = oof_df.merge(prices[[DATE_COL,'logret']], on=DATE_COL, how='left').sort_values(DATE_COL)\n",
        "    df['r1'] = df['logret'].shift(-1); df = df.dropna(subset=['r1']).reset_index(drop=True)\n",
        "    df['pos'] = (df['p_hat']>=thr).astype(int)\n",
        "    df['pos_shift'] = df['pos'].shift(1).fillna(0)\n",
        "    df['turnover']  = (df['pos_shift'] - df['pos_shift'].shift(1)).abs().fillna(df['pos_shift'].abs())\n",
        "    cost = (tc_bps/1e4)\n",
        "    df['ret_strategy'] = df['pos_shift']*df['r1'] - df['turnover']*cost\n",
        "    return df[[DATE_COL,'ret_strategy']]\n",
        "\n",
        "ret_df = backtest_ret_series(oo[[DATE_COL,'y_true','p_hat']], prices, thr, tc_bps=int(globals().get(\"TC_BPS\",5)))\n",
        "ret_df['roll_sharpe_6m'] = (\n",
        "    ret_df['ret_strategy'].rolling(WIN_DAYS).mean() / ret_df['ret_strategy'].rolling(WIN_DAYS).std(ddof=1)\n",
        ") * np.sqrt(252)\n",
        "\n",
        "# Save & show\n",
        "Path(\"artifacts/checks\").mkdir(parents=True, exist_ok=True)\n",
        "df_roll.to_csv(\"artifacts/checks/rolling_auc_mcc_6m.csv\", index=False)\n",
        "ret_df[[DATE_COL,'roll_sharpe_6m']].to_csv(\"artifacts/checks/rolling_sharpe_6m.csv\", index=False)\n",
        "\n",
        "print(\"Rolling 6M AUC/MCC (tail):\")\n",
        "display(df_roll.tail(10))\n",
        "print(\"\\nRolling 6M Sharpe (tail):\")\n",
        "display(ret_df[[DATE_COL,'roll_sharpe_6m']].tail(10))\n"
      ],
      "metadata": {
        "id": "_oFgPtKNleya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **19. Rolling AUC/MCC and rolling Sharpe (6-month windows)**"
      ],
      "metadata": {
        "id": "GQi943R1megP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot rolling AUC/MCC and rolling Sharpe from saved CSV artifacts.\n",
        "# This cell ONLY reads the CSVs produced earlier (18.3) and makes the plots.\n",
        "# If the CSVs are missing, it will print a helpful message.\n",
        "\n",
        "import pandas as pd, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "ARTDIR = Path(\"artifacts/checks\")\n",
        "roll_path   = ARTDIR / \"rolling_auc_mcc_6m.csv\"\n",
        "sharpe_path = ARTDIR / \"rolling_sharpe_6m.csv\"\n",
        "DATE_COL = \"Date\"  # plots use this label on the x-axis\n",
        "\n",
        "if not roll_path.exists() or not sharpe_path.exists():\n",
        "    print(\"Missing CSVs. Please run Section 18.3 first to create:\")\n",
        "    print(f\"- {roll_path}\")\n",
        "    print(f\"- {sharpe_path}\")\n",
        "else:\n",
        "    df_roll = pd.read_csv(roll_path)\n",
        "    # some earlier cells saved the date column as 'date'; normalize it\n",
        "    if 'date' in df_roll.columns and DATE_COL not in df_roll.columns:\n",
        "        df_roll.rename(columns={'date': DATE_COL}, inplace=True)\n",
        "    df_roll[DATE_COL] = pd.to_datetime(df_roll[DATE_COL])\n",
        "\n",
        "    df_sh = pd.read_csv(sharpe_path)\n",
        "    df_sh[DATE_COL] = pd.to_datetime(df_sh[DATE_COL])\n",
        "\n",
        "    # --- Plot 1: Rolling AUC & MCC ---\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(df_roll[DATE_COL], df_roll[\"auc_6m\"], label=\"Rolling AUC (6M)\")\n",
        "    plt.plot(df_roll[DATE_COL], df_roll[\"mcc_6m\"], label=\"Rolling MCC (6M)\")\n",
        "    plt.title(\"Rolling AUC & MCC (6-month window)\")\n",
        "    plt.xlabel(DATE_COL); plt.ylabel(\"Value\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTDIR / \"rolling_auc_mcc_6m.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot 2: Rolling Sharpe ---\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(df_sh[DATE_COL], df_sh[\"roll_sharpe_6m\"], label=\"Rolling Sharpe (6M)\")\n",
        "    plt.title(\"Rolling Sharpe (6-month window)\")\n",
        "    plt.xlabel(DATE_COL); plt.ylabel(\"Sharpe\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTDIR / \"rolling_sharpe_6m.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Saved plots to:\")\n",
        "    print(str(ARTDIR / \"rolling_auc_mcc_6m.png\"))\n",
        "    print(str(ARTDIR / \"rolling_sharpe_6m.png\"))\n"
      ],
      "metadata": {
        "id": "73ayvOvPmfEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ad75181"
      },
      "source": [
        "# **Summary and (Potential) Applications**\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "This notebook presents a framework for building and evaluating a time-series classification model using fractal and volatility features derived solely from past price data. The core methodology involves a rigorous walk-forward validation scheme with a purge period to ensure robustness and prevent look-ahead bias. Key aspects include probability calibration, threshold optimization for maximizing the Matthews Correlation Coefficient (MCC), and a basic PnL (Profit and Loss) sanity check.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Potential Use Cases and Applications:**\n",
        "\n",
        "*   **Algorithmic Trading Signals:** The primary application is generating directional trading signals (long/short or long-only) for various financial instruments based on the predicted price movements.\n",
        "*   **Risk Management:** The calibrated probabilities can be used for position sizing and risk management, allowing for more informed decisions based on the model's confidence.\n",
        "*   **Quantitative Research:** The framework provides a solid foundation for further quantitative research into the predictive power of fractal and volatility features in different market conditions and asset classes.\n",
        "*   **Feature Evaluation:** The permutation feature importance analysis helps identify which features are most relevant for prediction, guiding future feature engineering efforts.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Improving Real-World Performance and Applications:**\n",
        "\n",
        "The current model is intentionally limited to demonstrate a core framework with past-price features. For real-world applications, incorporating additional variables and parameters could significantly improve performance and broaden applicability:\n",
        "\n",
        "*   **External Data Sources:** Integrating macroeconomic indicators, news sentiment, fundamental data, or alternative data sources (e.g., satellite imagery, social media trends) could provide valuable context beyond price history.\n",
        "*   **Market Microstructure Data:** Including order book data, trade flow, and other high-frequency features could capture short-term market dynamics missed by daily or lower-frequency data.\n",
        "*   **Adaptive Learning:** Implementing adaptive learning techniques where the model is retrained or updated more frequently based on recent data could help it adapt to changing market regimes.\n",
        "*   **Transaction Cost Modeling:** More sophisticated modeling of transaction costs, including slippage based on order size and market liquidity, would provide a more realistic assessment of profitability.\n",
        "*   **Risk-Adjusted Optimization:** Optimizing not just for MCC but for risk-adjusted returns (e.g., Sharpe Ratio, Sortino Ratio) during threshold selection or even within the training objective could lead to more practical trading strategies.\n",
        "*   **Ensemble Methods:** Combining predictions from multiple models or different feature sets could improve robustness and predictive accuracy.\n",
        "*   **Deep Learning Models:** Exploring more complex deep learning architectures designed for sequence data (e.g., LSTMs, Transformers) could potentially capture more intricate patterns.\n",
        "*   **Dynamic Horizon/Barrier:** Instead of fixed horizons or barriers, dynamically adjusting them based on market volatility or other factors might yield better results."
      ]
    }
  ]
}